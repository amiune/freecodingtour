{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddf21d3d-9842-4239-bc7c-07732b46e80c",
   "metadata": {},
   "source": [
    "# AutoML: Machine Learning automatico\n",
    "\n",
    "El proceso de Machine Learning se puede automatizar un poco. Hay varios servicios en internet que lo hacen y tambien varias librerias. Aqui veremos la libreria FLAML de microsoft: \n",
    "- https://microsoft.github.io/FLAML/docs/Getting-Started/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccc23192-283f-40f3-98ca-bba6a1eb27a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flaml[automl] in /Users/hernanamiune/opt/anaconda3/lib/python3.9/site-packages (2.1.1)\n",
      "Requirement already satisfied: NumPy>=1.17.0rc1 in /Users/hernanamiune/opt/anaconda3/lib/python3.9/site-packages (from flaml[automl]) (1.26.1)\n",
      "Requirement already satisfied: xgboost>=0.90 in /Users/hernanamiune/opt/anaconda3/lib/python3.9/site-packages (from flaml[automl]) (1.5.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in /Users/hernanamiune/opt/anaconda3/lib/python3.9/site-packages (from flaml[automl]) (1.2.2)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/hernanamiune/opt/anaconda3/lib/python3.9/site-packages (from flaml[automl]) (1.4.2)\n",
      "Requirement already satisfied: lightgbm>=2.3.1 in /Users/hernanamiune/opt/anaconda3/lib/python3.9/site-packages (from flaml[automl]) (4.3.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/hernanamiune/opt/anaconda3/lib/python3.9/site-packages (from flaml[automl]) (1.10.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/hernanamiune/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.1.4->flaml[automl]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/hernanamiune/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.1.4->flaml[automl]) (2022.7)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/hernanamiune/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.24->flaml[automl]) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/hernanamiune/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.24->flaml[automl]) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/hernanamiune/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.1.4->flaml[automl]) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"flaml[automl]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66244623-92b7-4f7b-9807-dff7a879b649",
   "metadata": {},
   "source": [
    "Como vimos en la unidad anterior el proceso de Machine Learning culmina entrenando distintas cajas negras con distintos algoritmos y ajustando los parametros de dichos algoritmos para que el resultado del entrenamiento sea el mejor posible. Ahora veremos como utilizar la libreria FLAML para automatizar este proceso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8b7a646-be08-41fc-aa31-4e9e846e6b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17a6c801-c734-4893-8622-eef05fd2d683",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('https://raw.githubusercontent.com/amiune/freecodingtour/main/cursos/espanol/datascience/data/diabetes/diabetes_train_procesado.csv')\n",
    "df_test = pd.read_csv('https://raw.githubusercontent.com/amiune/freecodingtour/main/cursos/espanol/datascience/data/diabetes/diabetes_test_procesado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9dad325f-65c9-42e7-8ec6-a720fd77eaf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fuma</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>gimnasia</th>\n",
       "      <th>edad</th>\n",
       "      <th>altura</th>\n",
       "      <th>peso</th>\n",
       "      <th>presion1</th>\n",
       "      <th>presion2</th>\n",
       "      <th>colesterol_alto</th>\n",
       "      <th>colesterol_bajo</th>\n",
       "      <th>colesterol_medio</th>\n",
       "      <th>glucosa_alta</th>\n",
       "      <th>glucosa_baja</th>\n",
       "      <th>glucosa_media</th>\n",
       "      <th>sexo_f</th>\n",
       "      <th>sexo_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.119910</td>\n",
       "      <td>0.567395</td>\n",
       "      <td>0.126280</td>\n",
       "      <td>-0.175302</td>\n",
       "      <td>-0.086953</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.618194</td>\n",
       "      <td>0.079476</td>\n",
       "      <td>-0.639530</td>\n",
       "      <td>-0.054742</td>\n",
       "      <td>-0.076428</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.030711</td>\n",
       "      <td>0.689375</td>\n",
       "      <td>-1.266102</td>\n",
       "      <td>-0.054742</td>\n",
       "      <td>-0.086953</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.353273</td>\n",
       "      <td>0.567395</td>\n",
       "      <td>-0.848387</td>\n",
       "      <td>-0.054742</td>\n",
       "      <td>-0.086953</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.298867</td>\n",
       "      <td>0.201456</td>\n",
       "      <td>-0.500292</td>\n",
       "      <td>-0.054742</td>\n",
       "      <td>-0.086953</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fuma  alcohol  gimnasia      edad    altura      peso  presion1  presion2  \\\n",
       "0     0        0         1  0.119910  0.567395  0.126280 -0.175302 -0.086953   \n",
       "1     0        0         1 -0.618194  0.079476 -0.639530 -0.054742 -0.076428   \n",
       "2     0        0         1  1.030711  0.689375 -1.266102 -0.054742 -0.086953   \n",
       "3     0        0         0  0.353273  0.567395 -0.848387 -0.054742 -0.086953   \n",
       "4     0        0         0 -1.298867  0.201456 -0.500292 -0.054742 -0.086953   \n",
       "\n",
       "   colesterol_alto  colesterol_bajo  colesterol_medio  glucosa_alta  \\\n",
       "0                0                1                 0             0   \n",
       "1                0                1                 0             0   \n",
       "2                0                1                 0             0   \n",
       "3                0                1                 0             0   \n",
       "4                0                1                 0             0   \n",
       "\n",
       "   glucosa_baja  glucosa_media  sexo_f  sexo_m  \n",
       "0             1              0       1       0  \n",
       "1             1              0       0       1  \n",
       "2             1              0       0       1  \n",
       "3             1              0       0       1  \n",
       "4             1              0       0       1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_train.loc[:, df_train.columns != \"diabetes\"]\n",
    "y_train = df_train.loc[:, \"diabetes\"]\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8aff419-577d-4def-88b9-bff62871d52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 02-14 16:27:28] {1679} INFO - task = classification\n",
      "[flaml.automl.logger: 02-14 16:27:28] {1690} INFO - Evaluation method: holdout\n",
      "[flaml.automl.logger: 02-14 16:27:28] {1788} INFO - Minimizing error metric: 1-roc_auc\n",
      "[flaml.automl.logger: 02-14 16:27:28] {1900} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2344} INFO - Estimated sufficient time budget=858s. Estimated necessary time budget=20s.\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2391} INFO -  at 0.1s,\testimator lgbm's best error=0.0939,\tbest estimator lgbm's best error=0.0939\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2391} INFO -  at 0.2s,\testimator lgbm's best error=0.0939,\tbest estimator lgbm's best error=0.0939\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2391} INFO -  at 0.2s,\testimator lgbm's best error=0.0561,\tbest estimator lgbm's best error=0.0561\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2391} INFO -  at 0.2s,\testimator xgboost's best error=0.2719,\tbest estimator lgbm's best error=0.0561\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2391} INFO -  at 0.2s,\testimator lgbm's best error=0.0071,\tbest estimator lgbm's best error=0.0071\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2391} INFO -  at 0.2s,\testimator lgbm's best error=0.0071,\tbest estimator lgbm's best error=0.0071\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2391} INFO -  at 0.2s,\testimator lgbm's best error=0.0043,\tbest estimator lgbm's best error=0.0043\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2391} INFO -  at 0.2s,\testimator lgbm's best error=0.0043,\tbest estimator lgbm's best error=0.0043\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2391} INFO -  at 0.3s,\testimator lgbm's best error=0.0043,\tbest estimator lgbm's best error=0.0043\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2391} INFO -  at 0.3s,\testimator lgbm's best error=0.0019,\tbest estimator lgbm's best error=0.0019\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2391} INFO -  at 0.3s,\testimator xgboost's best error=0.2719,\tbest estimator lgbm's best error=0.0019\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 11, current learner extra_tree\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2391} INFO -  at 0.3s,\testimator extra_tree's best error=0.1015,\tbest estimator lgbm's best error=0.0019\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 12, current learner rf\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2391} INFO -  at 0.3s,\testimator rf's best error=0.1234,\tbest estimator lgbm's best error=0.0019\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2391} INFO -  at 0.4s,\testimator xgboost's best error=0.2204,\tbest estimator lgbm's best error=0.0019\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 14, current learner rf\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2391} INFO -  at 0.4s,\testimator rf's best error=0.0425,\tbest estimator lgbm's best error=0.0019\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2391} INFO -  at 0.4s,\testimator xgboost's best error=0.0961,\tbest estimator lgbm's best error=0.0019\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 16, current learner rf\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2391} INFO -  at 0.4s,\testimator rf's best error=0.0425,\tbest estimator lgbm's best error=0.0019\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 17, current learner extra_tree\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2391} INFO -  at 0.4s,\testimator extra_tree's best error=0.0747,\tbest estimator lgbm's best error=0.0019\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2391} INFO -  at 0.4s,\testimator lgbm's best error=0.0019,\tbest estimator lgbm's best error=0.0019\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2391} INFO -  at 0.5s,\testimator xgboost's best error=0.0961,\tbest estimator lgbm's best error=0.0019\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 20, current learner rf\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2391} INFO -  at 0.5s,\testimator rf's best error=0.0425,\tbest estimator lgbm's best error=0.0019\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2391} INFO -  at 0.5s,\testimator xgboost's best error=0.0961,\tbest estimator lgbm's best error=0.0019\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2391} INFO -  at 0.7s,\testimator lgbm's best error=0.0013,\tbest estimator lgbm's best error=0.0013\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 23, current learner rf\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2391} INFO -  at 0.7s,\testimator rf's best error=0.0336,\tbest estimator lgbm's best error=0.0013\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2391} INFO -  at 0.7s,\testimator extra_tree's best error=0.0747,\tbest estimator lgbm's best error=0.0013\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2391} INFO -  at 0.7s,\testimator extra_tree's best error=0.0747,\tbest estimator lgbm's best error=0.0013\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 26, current learner xgboost\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2391} INFO -  at 0.8s,\testimator xgboost's best error=0.0207,\tbest estimator lgbm's best error=0.0013\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 27, current learner xgboost\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2391} INFO -  at 0.8s,\testimator xgboost's best error=0.0055,\tbest estimator lgbm's best error=0.0013\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 28, current learner xgboost\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2391} INFO -  at 0.8s,\testimator xgboost's best error=0.0055,\tbest estimator lgbm's best error=0.0013\n",
      "[flaml.automl.logger: 02-14 16:27:28] {2218} INFO - iteration 29, current learner xgboost\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2391} INFO -  at 0.8s,\testimator xgboost's best error=0.0055,\tbest estimator lgbm's best error=0.0013\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2218} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2391} INFO -  at 1.0s,\testimator lgbm's best error=0.0013,\tbest estimator lgbm's best error=0.0013\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2218} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2391} INFO -  at 1.1s,\testimator lgbm's best error=0.0013,\tbest estimator lgbm's best error=0.0013\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2218} INFO - iteration 32, current learner xgboost\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2391} INFO -  at 1.2s,\testimator xgboost's best error=0.0047,\tbest estimator lgbm's best error=0.0013\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2218} INFO - iteration 33, current learner extra_tree\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2391} INFO -  at 1.2s,\testimator extra_tree's best error=0.0490,\tbest estimator lgbm's best error=0.0013\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2218} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2391} INFO -  at 1.3s,\testimator lgbm's best error=0.0012,\tbest estimator lgbm's best error=0.0012\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2218} INFO - iteration 35, current learner xgboost\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2391} INFO -  at 1.3s,\testimator xgboost's best error=0.0047,\tbest estimator lgbm's best error=0.0012\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2218} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2391} INFO -  at 1.3s,\testimator extra_tree's best error=0.0490,\tbest estimator lgbm's best error=0.0012\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2218} INFO - iteration 37, current learner xgboost\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2391} INFO -  at 1.4s,\testimator xgboost's best error=0.0047,\tbest estimator lgbm's best error=0.0012\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2218} INFO - iteration 38, current learner extra_tree\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2391} INFO -  at 1.4s,\testimator extra_tree's best error=0.0382,\tbest estimator lgbm's best error=0.0012\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2218} INFO - iteration 39, current learner rf\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2391} INFO -  at 1.4s,\testimator rf's best error=0.0336,\tbest estimator lgbm's best error=0.0012\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2218} INFO - iteration 40, current learner extra_tree\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2391} INFO -  at 1.5s,\testimator extra_tree's best error=0.0312,\tbest estimator lgbm's best error=0.0012\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2218} INFO - iteration 41, current learner extra_tree\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2391} INFO -  at 1.5s,\testimator extra_tree's best error=0.0312,\tbest estimator lgbm's best error=0.0012\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2218} INFO - iteration 42, current learner lgbm\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2391} INFO -  at 1.6s,\testimator lgbm's best error=0.0012,\tbest estimator lgbm's best error=0.0012\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2218} INFO - iteration 43, current learner extra_tree\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2391} INFO -  at 1.7s,\testimator extra_tree's best error=0.0312,\tbest estimator lgbm's best error=0.0012\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2218} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2391} INFO -  at 1.7s,\testimator extra_tree's best error=0.0161,\tbest estimator lgbm's best error=0.0012\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2218} INFO - iteration 45, current learner extra_tree\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2391} INFO -  at 1.8s,\testimator extra_tree's best error=0.0161,\tbest estimator lgbm's best error=0.0012\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2218} INFO - iteration 46, current learner rf\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2391} INFO -  at 1.8s,\testimator rf's best error=0.0212,\tbest estimator lgbm's best error=0.0012\n",
      "[flaml.automl.logger: 02-14 16:27:29] {2218} INFO - iteration 47, current learner extra_tree\n",
      "[flaml.automl.logger: 02-14 16:27:30] {2391} INFO -  at 1.8s,\testimator extra_tree's best error=0.0103,\tbest estimator lgbm's best error=0.0012\n",
      "[flaml.automl.logger: 02-14 16:27:30] {2218} INFO - iteration 48, current learner lgbm\n",
      "[flaml.automl.logger: 02-14 16:27:30] {2391} INFO -  at 2.0s,\testimator lgbm's best error=0.0012,\tbest estimator lgbm's best error=0.0012\n",
      "[flaml.automl.logger: 02-14 16:27:30] {2218} INFO - iteration 49, current learner rf\n",
      "[flaml.automl.logger: 02-14 16:27:30] {2391} INFO -  at 2.1s,\testimator rf's best error=0.0110,\tbest estimator lgbm's best error=0.0012\n",
      "[flaml.automl.logger: 02-14 16:27:30] {2218} INFO - iteration 50, current learner extra_tree\n",
      "[flaml.automl.logger: 02-14 16:27:30] {2391} INFO -  at 2.1s,\testimator extra_tree's best error=0.0099,\tbest estimator lgbm's best error=0.0012\n",
      "[flaml.automl.logger: 02-14 16:27:30] {2218} INFO - iteration 51, current learner rf\n",
      "[flaml.automl.logger: 02-14 16:27:30] {2391} INFO -  at 2.2s,\testimator rf's best error=0.0110,\tbest estimator lgbm's best error=0.0012\n",
      "[flaml.automl.logger: 02-14 16:27:30] {2218} INFO - iteration 52, current learner rf\n",
      "[flaml.automl.logger: 02-14 16:27:30] {2391} INFO -  at 2.2s,\testimator rf's best error=0.0110,\tbest estimator lgbm's best error=0.0012\n",
      "[flaml.automl.logger: 02-14 16:27:30] {2218} INFO - iteration 53, current learner lgbm\n",
      "[flaml.automl.logger: 02-14 16:27:30] {2391} INFO -  at 2.3s,\testimator lgbm's best error=0.0012,\tbest estimator lgbm's best error=0.0012\n",
      "[flaml.automl.logger: 02-14 16:27:30] {2218} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl.logger: 02-14 16:27:30] {2391} INFO -  at 2.6s,\testimator lgbm's best error=0.0008,\tbest estimator lgbm's best error=0.0008\n",
      "[flaml.automl.logger: 02-14 16:27:30] {2218} INFO - iteration 55, current learner rf\n",
      "[flaml.automl.logger: 02-14 16:27:30] {2391} INFO -  at 2.6s,\testimator rf's best error=0.0056,\tbest estimator lgbm's best error=0.0008\n",
      "[flaml.automl.logger: 02-14 16:27:30] {2218} INFO - iteration 56, current learner rf\n",
      "[flaml.automl.logger: 02-14 16:27:30] {2391} INFO -  at 2.7s,\testimator rf's best error=0.0056,\tbest estimator lgbm's best error=0.0008\n",
      "[flaml.automl.logger: 02-14 16:27:30] {2218} INFO - iteration 57, current learner rf\n",
      "[flaml.automl.logger: 02-14 16:27:30] {2391} INFO -  at 2.7s,\testimator rf's best error=0.0043,\tbest estimator lgbm's best error=0.0008\n",
      "[flaml.automl.logger: 02-14 16:27:30] {2218} INFO - iteration 58, current learner rf\n",
      "[flaml.automl.logger: 02-14 16:27:30] {2391} INFO -  at 2.8s,\testimator rf's best error=0.0043,\tbest estimator lgbm's best error=0.0008\n",
      "[flaml.automl.logger: 02-14 16:27:30] {2218} INFO - iteration 59, current learner lgbm\n",
      "[flaml.automl.logger: 02-14 16:27:31] {2391} INFO -  at 3.1s,\testimator lgbm's best error=0.0002,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:31] {2218} INFO - iteration 60, current learner rf\n",
      "[flaml.automl.logger: 02-14 16:27:31] {2391} INFO -  at 3.2s,\testimator rf's best error=0.0043,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:31] {2218} INFO - iteration 61, current learner lgbm\n",
      "[flaml.automl.logger: 02-14 16:27:31] {2391} INFO -  at 3.5s,\testimator lgbm's best error=0.0002,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:31] {2218} INFO - iteration 62, current learner lgbm\n",
      "[flaml.automl.logger: 02-14 16:27:31] {2391} INFO -  at 3.6s,\testimator lgbm's best error=0.0002,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:31] {2218} INFO - iteration 63, current learner xgboost\n",
      "[flaml.automl.logger: 02-14 16:27:31] {2391} INFO -  at 3.6s,\testimator xgboost's best error=0.0047,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:31] {2218} INFO - iteration 64, current learner lgbm\n",
      "[flaml.automl.logger: 02-14 16:27:32] {2391} INFO -  at 4.5s,\testimator lgbm's best error=0.0002,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:32] {2218} INFO - iteration 65, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-14 16:27:32] {2391} INFO -  at 4.6s,\testimator xgb_limitdepth's best error=0.0054,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:32] {2218} INFO - iteration 66, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-14 16:27:32] {2391} INFO -  at 4.6s,\testimator xgb_limitdepth's best error=0.0054,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:32] {2218} INFO - iteration 67, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-14 16:27:32] {2391} INFO -  at 4.7s,\testimator xgb_limitdepth's best error=0.0040,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:32] {2218} INFO - iteration 68, current learner xgboost\n",
      "[flaml.automl.logger: 02-14 16:27:32] {2391} INFO -  at 4.7s,\testimator xgboost's best error=0.0027,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:32] {2218} INFO - iteration 69, current learner lgbm\n",
      "[flaml.automl.logger: 02-14 16:27:33] {2391} INFO -  at 5.1s,\testimator lgbm's best error=0.0002,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:33] {2218} INFO - iteration 70, current learner xgboost\n",
      "[flaml.automl.logger: 02-14 16:27:33] {2391} INFO -  at 5.1s,\testimator xgboost's best error=0.0027,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:33] {2218} INFO - iteration 71, current learner extra_tree\n",
      "[flaml.automl.logger: 02-14 16:27:33] {2391} INFO -  at 5.2s,\testimator extra_tree's best error=0.0099,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:33] {2218} INFO - iteration 72, current learner xgboost\n",
      "[flaml.automl.logger: 02-14 16:27:33] {2391} INFO -  at 5.2s,\testimator xgboost's best error=0.0012,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:33] {2218} INFO - iteration 73, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-14 16:27:33] {2391} INFO -  at 5.3s,\testimator xgb_limitdepth's best error=0.0035,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:33] {2218} INFO - iteration 74, current learner xgboost\n",
      "[flaml.automl.logger: 02-14 16:27:33] {2391} INFO -  at 5.3s,\testimator xgboost's best error=0.0012,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:33] {2218} INFO - iteration 75, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-14 16:27:33] {2391} INFO -  at 5.4s,\testimator xgb_limitdepth's best error=0.0035,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:33] {2218} INFO - iteration 76, current learner xgboost\n",
      "[flaml.automl.logger: 02-14 16:27:33] {2391} INFO -  at 5.4s,\testimator xgboost's best error=0.0012,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:33] {2218} INFO - iteration 77, current learner rf\n",
      "[flaml.automl.logger: 02-14 16:27:33] {2391} INFO -  at 5.5s,\testimator rf's best error=0.0043,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:33] {2218} INFO - iteration 78, current learner xgboost\n",
      "[flaml.automl.logger: 02-14 16:27:33] {2391} INFO -  at 5.5s,\testimator xgboost's best error=0.0012,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:33] {2218} INFO - iteration 79, current learner xgboost\n",
      "[flaml.automl.logger: 02-14 16:27:33] {2391} INFO -  at 5.6s,\testimator xgboost's best error=0.0012,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:33] {2218} INFO - iteration 80, current learner rf\n",
      "[flaml.automl.logger: 02-14 16:27:33] {2391} INFO -  at 5.7s,\testimator rf's best error=0.0043,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:33] {2218} INFO - iteration 81, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-14 16:27:33] {2391} INFO -  at 5.7s,\testimator xgb_limitdepth's best error=0.0035,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:33] {2218} INFO - iteration 82, current learner xgboost\n",
      "[flaml.automl.logger: 02-14 16:27:34] {2391} INFO -  at 5.8s,\testimator xgboost's best error=0.0012,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:34] {2218} INFO - iteration 83, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-14 16:27:34] {2391} INFO -  at 5.9s,\testimator xgb_limitdepth's best error=0.0023,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:34] {2218} INFO - iteration 84, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-14 16:27:34] {2391} INFO -  at 6.0s,\testimator xgb_limitdepth's best error=0.0021,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:34] {2218} INFO - iteration 85, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-14 16:27:34] {2391} INFO -  at 6.1s,\testimator xgb_limitdepth's best error=0.0021,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:34] {2218} INFO - iteration 86, current learner xgboost\n",
      "[flaml.automl.logger: 02-14 16:27:34] {2391} INFO -  at 6.2s,\testimator xgboost's best error=0.0010,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:34] {2218} INFO - iteration 87, current learner xgboost\n",
      "[flaml.automl.logger: 02-14 16:27:34] {2391} INFO -  at 6.3s,\testimator xgboost's best error=0.0010,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:34] {2218} INFO - iteration 88, current learner rf\n",
      "[flaml.automl.logger: 02-14 16:27:34] {2391} INFO -  at 6.5s,\testimator rf's best error=0.0022,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:34] {2218} INFO - iteration 89, current learner rf\n",
      "[flaml.automl.logger: 02-14 16:27:34] {2391} INFO -  at 6.6s,\testimator rf's best error=0.0022,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:34] {2218} INFO - iteration 90, current learner extra_tree\n",
      "[flaml.automl.logger: 02-14 16:27:34] {2391} INFO -  at 6.6s,\testimator extra_tree's best error=0.0080,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:34] {2218} INFO - iteration 91, current learner xgboost\n",
      "[flaml.automl.logger: 02-14 16:27:34] {2391} INFO -  at 6.7s,\testimator xgboost's best error=0.0010,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:34] {2218} INFO - iteration 92, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-14 16:27:35] {2391} INFO -  at 6.8s,\testimator xgb_limitdepth's best error=0.0020,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:35] {2218} INFO - iteration 93, current learner extra_tree\n",
      "[flaml.automl.logger: 02-14 16:27:35] {2391} INFO -  at 6.8s,\testimator extra_tree's best error=0.0080,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:35] {2218} INFO - iteration 94, current learner xgboost\n",
      "[flaml.automl.logger: 02-14 16:27:35] {2391} INFO -  at 7.1s,\testimator xgboost's best error=0.0007,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:35] {2218} INFO - iteration 95, current learner lgbm\n",
      "[flaml.automl.logger: 02-14 16:27:35] {2391} INFO -  at 7.3s,\testimator lgbm's best error=0.0002,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:35] {2218} INFO - iteration 96, current learner extra_tree\n",
      "[flaml.automl.logger: 02-14 16:27:35] {2391} INFO -  at 7.3s,\testimator extra_tree's best error=0.0080,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:35] {2218} INFO - iteration 97, current learner rf\n",
      "[flaml.automl.logger: 02-14 16:27:35] {2391} INFO -  at 7.6s,\testimator rf's best error=0.0022,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:35] {2218} INFO - iteration 98, current learner xgboost\n",
      "[flaml.automl.logger: 02-14 16:27:35] {2391} INFO -  at 7.7s,\testimator xgboost's best error=0.0007,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:35] {2218} INFO - iteration 99, current learner rf\n",
      "[flaml.automl.logger: 02-14 16:27:36] {2391} INFO -  at 7.9s,\testimator rf's best error=0.0017,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:36] {2218} INFO - iteration 100, current learner rf\n",
      "[flaml.automl.logger: 02-14 16:27:36] {2391} INFO -  at 8.1s,\testimator rf's best error=0.0017,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:36] {2218} INFO - iteration 101, current learner extra_tree\n",
      "[flaml.automl.logger: 02-14 16:27:36] {2391} INFO -  at 8.1s,\testimator extra_tree's best error=0.0036,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:36] {2218} INFO - iteration 102, current learner extra_tree\n",
      "[flaml.automl.logger: 02-14 16:27:36] {2391} INFO -  at 8.1s,\testimator extra_tree's best error=0.0036,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:36] {2218} INFO - iteration 103, current learner lgbm\n",
      "[flaml.automl.logger: 02-14 16:27:36] {2391} INFO -  at 8.4s,\testimator lgbm's best error=0.0002,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:36] {2218} INFO - iteration 104, current learner extra_tree\n",
      "[flaml.automl.logger: 02-14 16:27:36] {2391} INFO -  at 8.5s,\testimator extra_tree's best error=0.0036,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:36] {2218} INFO - iteration 105, current learner extra_tree\n",
      "[flaml.automl.logger: 02-14 16:27:36] {2391} INFO -  at 8.5s,\testimator extra_tree's best error=0.0034,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:36] {2218} INFO - iteration 106, current learner xgboost\n",
      "[flaml.automl.logger: 02-14 16:27:37] {2391} INFO -  at 9.4s,\testimator xgboost's best error=0.0007,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:37] {2218} INFO - iteration 107, current learner extra_tree\n",
      "[flaml.automl.logger: 02-14 16:27:37] {2391} INFO -  at 9.4s,\testimator extra_tree's best error=0.0034,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:37] {2218} INFO - iteration 108, current learner lgbm\n",
      "[flaml.automl.logger: 02-14 16:27:37] {2391} INFO -  at 9.8s,\testimator lgbm's best error=0.0002,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:37] {2218} INFO - iteration 109, current learner lrl1\n",
      "[flaml.automl.logger: 02-14 16:27:38] {2391} INFO -  at 9.9s,\testimator lrl1's best error=0.0071,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:38] {2218} INFO - iteration 110, current learner extra_tree\n",
      "[flaml.automl.logger: 02-14 16:27:38] {2391} INFO -  at 10.0s,\testimator extra_tree's best error=0.0034,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 02-14 16:27:38] {2627} INFO - retrain lgbm for 0.4s\n",
      "[flaml.automl.logger: 02-14 16:27:38] {2630} INFO - retrained model: LGBMClassifier(colsample_bytree=0.8144610352665659,\n",
      "               learning_rate=0.28491500484442356, max_bin=1023,\n",
      "               min_child_samples=2, n_estimators=1, n_jobs=-1, num_leaves=17,\n",
      "               reg_alpha=0.0009765625, reg_lambda=0.04528736269543623,\n",
      "               verbose=-1)\n",
      "[flaml.automl.logger: 02-14 16:27:38] {1930} INFO - fit succeeded\n",
      "[flaml.automl.logger: 02-14 16:27:38] {1931} INFO - Time taken to find the best model: 3.0961010456085205\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "automl = AutoML()\n",
    "automl.fit(X_train, y_train, task=\"classification\", time_budget=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9a776c0-9df4-46fe-9858-9fc91e328a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__del__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__version__',\n",
       " '__weakref__',\n",
       " '_active_estimators',\n",
       " '_auto_augment',\n",
       " '_best_estimator',\n",
       " '_best_iteration',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_config_history',\n",
       " '_decide_eval_method',\n",
       " '_df',\n",
       " '_early_stop',\n",
       " '_eci',\n",
       " '_ensemble',\n",
       " '_estimator_index',\n",
       " '_estimator_type',\n",
       " '_feature_names_in_',\n",
       " '_force_cancel',\n",
       " '_fullsize_reached',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_hpo_method',\n",
       " '_iter_per_learner',\n",
       " '_iter_per_learner_fullsize',\n",
       " '_label_transformer',\n",
       " '_learner_selector',\n",
       " '_log_trial',\n",
       " '_log_type',\n",
       " '_max_iter',\n",
       " '_max_iter_per_learner',\n",
       " '_mem_thres',\n",
       " '_metric_constraints',\n",
       " '_min_sample_size',\n",
       " '_min_sample_size_input',\n",
       " '_mlflow_logging',\n",
       " '_more_tags',\n",
       " '_n_concurrent_trials',\n",
       " '_ndim',\n",
       " '_nrow',\n",
       " '_pred_time_limit',\n",
       " '_prepare_data',\n",
       " '_random',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_retrain_in_budget',\n",
       " '_retrained_config',\n",
       " '_sample',\n",
       " '_search',\n",
       " '_search_parallel',\n",
       " '_search_sequential',\n",
       " '_search_states',\n",
       " '_seed',\n",
       " '_select_estimator',\n",
       " '_selected',\n",
       " '_settings',\n",
       " '_skip_transform',\n",
       " '_split_type',\n",
       " '_start_time_flag',\n",
       " '_state',\n",
       " '_time_taken_best_iter',\n",
       " '_track_iter',\n",
       " '_trained_estimator',\n",
       " '_training_log',\n",
       " '_transformer',\n",
       " '_use_ray',\n",
       " '_use_spark',\n",
       " '_validate_data',\n",
       " '_validate_params',\n",
       " '_warn_threshold',\n",
       " 'add_learner',\n",
       " 'best_config',\n",
       " 'best_config_per_estimator',\n",
       " 'best_config_train_time',\n",
       " 'best_estimator',\n",
       " 'best_iteration',\n",
       " 'best_loss',\n",
       " 'best_loss_per_estimator',\n",
       " 'best_model_for_estimator',\n",
       " 'best_result',\n",
       " 'cat_hp_cost',\n",
       " 'classes_',\n",
       " 'config_history',\n",
       " 'data_size_full',\n",
       " 'estimator_list',\n",
       " 'feature_importances_',\n",
       " 'feature_names_in_',\n",
       " 'feature_transformer',\n",
       " 'fit',\n",
       " 'get_estimator_from_log',\n",
       " 'get_params',\n",
       " 'label_transformer',\n",
       " 'low_cost_partial_config',\n",
       " 'max_resource',\n",
       " 'metric_constraints',\n",
       " 'metrics_for_best_config',\n",
       " 'min_resource',\n",
       " 'model',\n",
       " 'modelcount',\n",
       " 'n_features_in_',\n",
       " 'pickle',\n",
       " 'points_to_evaluate',\n",
       " 'predict',\n",
       " 'predict_proba',\n",
       " 'preserve_checkpoint',\n",
       " 'resource_attr',\n",
       " 'retrain_from_log',\n",
       " 'save_best_config',\n",
       " 'score',\n",
       " 'search_space',\n",
       " 'set_params',\n",
       " 'split_ratio',\n",
       " 'time_to_find_best_model',\n",
       " 'trainable',\n",
       " 'verbose']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(automl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d296d3c4-0bd0-41a9-bc69-c0c79ed0e4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lgbm'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13bec73d-e498-4a41-9853-391bbfc86bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 183,\n",
       " 'num_leaves': 17,\n",
       " 'min_child_samples': 2,\n",
       " 'learning_rate': 0.28491500484442356,\n",
       " 'log_max_bin': 10,\n",
       " 'colsample_bytree': 0.8144610352665659,\n",
       " 'reg_alpha': 0.0009765625,\n",
       " 'reg_lambda': 0.04528736269543623}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.best_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1686a63d-1f84-4b1b-8295-4328a2f82ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00021278220517995106"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa18feb6-714a-4c6b-8255-83bdbb4df418",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.loc[:, df_test.columns != \"diabetes\"]\n",
    "y_test = df_test.loc[:, \"diabetes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aaa37a55-9ad9-451c-9a3e-d331d403270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def calcular_accuracy_train_val(clf, X_train, y_train, X_val, y_val):\n",
    "    #clf.fit(X_train,y_train)\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "    print(\"Entrenamiento accuracy:\",accuracy_score(y_train, y_train_pred))\n",
    "    y_val_pred = clf.predict(X_val)\n",
    "    print(\"Validacion accuracy:\",accuracy_score(y_val, y_val_pred))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aae366e5-f1e3-46ec-9fff-bce6a1cd5250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento accuracy: 0.99935\n",
      "Validacion accuracy: 0.9922\n"
     ]
    }
   ],
   "source": [
    "clf = calcular_accuracy_train_val(automl, X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
