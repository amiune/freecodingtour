{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediccion de Series de Tiempo (Time Series Forecasting)\n",
    "\n",
    "Una serie de tiempo es una secuencia de datos ordenados cronologicamente. Por ejemplo: la temperatura diaria, el precio de una accion, la cantidad de pasajeros de una aerolinea por mes, etc.\n",
    "\n",
    "En esta notebook aprenderemos:\n",
    "1. Los tres componentes de una serie de tiempo\n",
    "2. Como descomponer una serie en sus componentes\n",
    "3. Como predecir valores futuros utilizando tres enfoques distintos:\n",
    "   - **ARIMA**: el algoritmo clasico de series de tiempo\n",
    "   - **LightGBM**: un algoritmo de Gradient Boosting adaptado para series de tiempo\n",
    "   - **NHITS**: una red neuronal moderna disenada para series de tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statsmodels lightgbm neuralforecast -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar y visualizar los datos\n",
    "\n",
    "Utilizaremos el clasico dataset de **AirPassengers** que contiene la cantidad mensual de pasajeros de una aerolinea internacional entre 1949 y 1960."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv'\n",
    "df = pd.read_csv(url)\n",
    "df.columns = ['fecha', 'pasajeros']\n",
    "df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "df = df.set_index('fecha')\n",
    "print(f\"Cantidad de observaciones: {len(df)}\")\n",
    "print(f\"Periodo: {df.index[0].strftime('%Y-%m')} a {df.index[-1].strftime('%Y-%m')}\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(figsize=(12, 4), title='Pasajeros de aerolinea por mes')\n",
    "plt.ylabel('Pasajeros (miles)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que la cantidad de pasajeros crece con el tiempo y que cada anio se repite un patron similar. Esto nos lleva a hablar de los tres componentes fundamentales de una serie de tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Los tres componentes de una serie de tiempo\n",
    "\n",
    "Toda serie de tiempo se puede descomponer en tres componentes fundamentales:\n",
    "\n",
    "### 1. Tendencia (Trend)\n",
    "Es la direccion general a largo plazo de los datos. Puede ser creciente, decreciente o constante. En nuestro ejemplo, la cantidad de pasajeros tiene una clara **tendencia creciente** a lo largo de los anios.\n",
    "\n",
    "### 2. Estacionalidad (Seasonality)\n",
    "Son patrones que se repiten de forma regular en intervalos fijos de tiempo. En nuestro ejemplo, cada anio se repite un patron similar: **mas pasajeros en verano y menos en invierno**.\n",
    "\n",
    "### 3. Residuo (Residual)\n",
    "Es lo que queda despues de eliminar la tendencia y la estacionalidad. Representa **variaciones aleatorias o ruido** que no se puede explicar con los otros dos componentes.\n",
    "\n",
    "La descomposicion puede ser:\n",
    "- **Aditiva**: Serie = Tendencia + Estacionalidad + Residuo (cuando la variacion estacional es constante)\n",
    "- **Multiplicativa**: Serie = Tendencia x Estacionalidad x Residuo (cuando la variacion estacional crece con la tendencia)\n",
    "\n",
    "En nuestro caso, como la amplitud de las oscilaciones crece con el tiempo, usaremos descomposicion **multiplicativa**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "result = seasonal_decompose(df['pasajeros'], model='multiplicative', period=12)\n",
    "\n",
    "fig = result.plot()\n",
    "fig.set_size_inches(12, 8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver claramente los tres componentes:\n",
    "- **Tendencia (Trend)**: crecimiento continuo de pasajeros\n",
    "- **Estacionalidad (Seasonal)**: un patron que se repite cada 12 meses con picos en julio/agosto\n",
    "- **Residuo (Resid)**: variaciones aleatorias que no siguen ningun patron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar datos de entrenamiento y prueba\n",
    "\n",
    "En series de tiempo, la division de datos **siempre debe ser cronologica**: entrenamos con el pasado y evaluamos con el futuro. Nunca se mezclan datos aleatoriamente como en otros problemas de Machine Learning.\n",
    "\n",
    "Usaremos los datos hasta diciembre de 1959 para entrenar y los 12 meses de 1960 para evaluar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df.index < '1960-01-01']\n",
    "test = df[df.index >= '1960-01-01']\n",
    "\n",
    "print(f\"Entrenamiento: {len(train)} observaciones ({train.index[0].strftime('%Y-%m')} a {train.index[-1].strftime('%Y-%m')})\")\n",
    "print(f\"Prueba: {len(test)} observaciones ({test.index[0].strftime('%Y-%m')} a {test.index[-1].strftime('%Y-%m')})\")\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(train.index, train['pasajeros'], label='Entrenamiento')\n",
    "plt.plot(test.index, test['pasajeros'], label='Prueba', color='orange')\n",
    "plt.legend()\n",
    "plt.title('Division cronologica de los datos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crearemos una funcion para evaluar las metricas de cada modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def evaluar_modelo(nombre, real, prediccion):\n",
    "    mae = mean_absolute_error(real, prediccion)\n",
    "    rmse = np.sqrt(mean_squared_error(real, prediccion))\n",
    "    mape = np.mean(np.abs((real - prediccion) / real)) * 100\n",
    "    print(f\"{nombre}:\")\n",
    "    print(f\"  MAE  = {mae:.2f}\")\n",
    "    print(f\"  RMSE = {rmse:.2f}\")\n",
    "    print(f\"  MAPE = {mape:.2f}%\")\n",
    "    return {'modelo': nombre, 'MAE': round(mae, 2), 'RMSE': round(rmse, 2), 'MAPE': round(mape, 2)}\n",
    "\n",
    "resultados = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 1: ARIMA\n",
    "\n",
    "[ARIMA](https://es.wikipedia.org/wiki/Modelo_autorregresivo_integrado_de_media_m%C3%B3vil) (AutoRegressive Integrated Moving Average) es el algoritmo clasico para series de tiempo. Tiene tres parametros principales:\n",
    "\n",
    "- **p** (AutoRegressive): cuantos valores pasados se usan para predecir el siguiente\n",
    "- **d** (Integrated): cuantas veces se diferencia la serie para hacerla estacionaria\n",
    "- **q** (Moving Average): cuantos errores pasados se usan para corregir la prediccion\n",
    "\n",
    "Para datos con estacionalidad usamos **SARIMA** que agrega parametros estacionales **(P, D, Q, m)** donde **m** es el periodo estacional (12 para datos mensuales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "model_arima = SARIMAX(train['pasajeros'], \n",
    "                       order=(1, 1, 1), \n",
    "                       seasonal_order=(1, 1, 1, 12))\n",
    "model_arima_fit = model_arima.fit(disp=False)\n",
    "\n",
    "pred_arima = model_arima_fit.forecast(steps=12)\n",
    "pred_arima.index = test.index\n",
    "\n",
    "r = evaluar_modelo('ARIMA', test['pasajeros'].values, pred_arima.values)\n",
    "resultados.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(train.index, train['pasajeros'], label='Entrenamiento')\n",
    "plt.plot(test.index, test['pasajeros'], label='Real', marker='o')\n",
    "plt.plot(test.index, pred_arima, label='ARIMA', marker='x', linestyle='--')\n",
    "plt.legend()\n",
    "plt.title('Prediccion con ARIMA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 2: Gradient Boosting con LightGBM\n",
    "\n",
    "Los algoritmos de Gradient Boosting como [LightGBM](https://lightgbm.readthedocs.io/) no estan disenados especificamente para series de tiempo, pero podemos adaptarlos creando variables (features) a partir de la serie temporal:\n",
    "\n",
    "- **Valores pasados (lags)**: el valor de hace 1 mes, 2 meses, ..., 12 meses\n",
    "- **Variables de fecha**: mes del anio\n",
    "- **Estadisticas moviles**: media movil de los ultimos 12 meses\n",
    "\n",
    "Este proceso de crear variables se llama **feature engineering** y es clave para que estos algoritmos funcionen bien con series de tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_features(dataframe, lags=12):\n",
    "    df_feat = dataframe.copy()\n",
    "    df_feat['mes'] = df_feat.index.month\n",
    "    df_feat['anio'] = df_feat.index.year\n",
    "    for i in range(1, lags + 1):\n",
    "        df_feat[f'lag_{i}'] = df_feat['pasajeros'].shift(i)\n",
    "    df_feat['media_movil_12'] = df_feat['pasajeros'].shift(1).rolling(12).mean()\n",
    "    df_feat = df_feat.dropna()\n",
    "    return df_feat\n",
    "\n",
    "df_features = crear_features(df)\n",
    "print(f\"Features creados: {list(df_features.columns)}\")\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "train_feat = df_features[df_features.index < '1960-01-01']\n",
    "test_feat = df_features[df_features.index >= '1960-01-01']\n",
    "\n",
    "X_train_lgb = train_feat.drop(columns=['pasajeros'])\n",
    "y_train_lgb = train_feat['pasajeros']\n",
    "X_test_lgb = test_feat.drop(columns=['pasajeros'])\n",
    "y_test_lgb = test_feat['pasajeros']\n",
    "\n",
    "model_lgb = lgb.LGBMRegressor(n_estimators=200, learning_rate=0.1, \n",
    "                               num_leaves=31, random_state=42, verbose=-1)\n",
    "model_lgb.fit(X_train_lgb, y_train_lgb)\n",
    "pred_lgb = model_lgb.predict(X_test_lgb)\n",
    "\n",
    "r = evaluar_modelo('LightGBM', y_test_lgb.values, pred_lgb)\n",
    "resultados.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(train.index, train['pasajeros'], label='Entrenamiento')\n",
    "plt.plot(test.index, test['pasajeros'], label='Real', marker='o')\n",
    "plt.plot(test.index, pred_lgb, label='LightGBM', marker='x', linestyle='--')\n",
    "plt.legend()\n",
    "plt.title('Prediccion con LightGBM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver cuales features fueron mas importantes para el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importancia = pd.DataFrame({\n",
    "    'feature': X_train_lgb.columns,\n",
    "    'importancia': model_lgb.feature_importances_\n",
    "}).sort_values('importancia', ascending=True)\n",
    "\n",
    "importancia.plot(x='feature', y='importancia', kind='barh', figsize=(8, 5), legend=False)\n",
    "plt.title('Importancia de features en LightGBM')\n",
    "plt.xlabel('Importancia')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 3: Red Neuronal NHITS\n",
    "\n",
    "[NHITS](https://arxiv.org/abs/2201.12886) (Neural Hierarchical Interpolation for Time Series) es una red neuronal moderna disenada especificamente para prediccion de series de tiempo. Es una evolucion de [N-BEATS](https://arxiv.org/abs/1905.10437) que utiliza interpolacion jerarquica para capturar patrones a diferentes escalas temporales.\n",
    "\n",
    "Utilizaremos la libreria [NeuralForecast](https://nixtla.github.io/neuralforecast/) de Nixtla que nos permite usar redes neuronales avanzadas de forma sencilla.\n",
    "\n",
    "La libreria requiere un formato especifico con tres columnas:\n",
    "- **unique_id**: identificador de la serie\n",
    "- **ds**: fecha\n",
    "- **y**: valor a predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NHITS\n",
    "\n",
    "df_nf = df.reset_index()\n",
    "df_nf.columns = ['ds', 'y']\n",
    "df_nf['unique_id'] = 'pasajeros'\n",
    "df_nf = df_nf[['unique_id', 'ds', 'y']]\n",
    "\n",
    "train_nf = df_nf[df_nf['ds'] < '1960-01-01']\n",
    "\n",
    "horizon = 12\n",
    "\n",
    "model_nhits = NeuralForecast(\n",
    "    models=[NHITS(h=horizon, input_size=24, max_steps=300)],\n",
    "    freq='MS'\n",
    ")\n",
    "model_nhits.fit(df=train_nf)\n",
    "pred_nhits_df = model_nhits.predict()\n",
    "\n",
    "pred_nhits = pred_nhits_df['NHITS'].values\n",
    "\n",
    "r = evaluar_modelo('NHITS', test['pasajeros'].values, pred_nhits)\n",
    "resultados.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(train.index, train['pasajeros'], label='Entrenamiento')\n",
    "plt.plot(test.index, test['pasajeros'], label='Real', marker='o')\n",
    "plt.plot(test.index, pred_nhits, label='NHITS', marker='x', linestyle='--')\n",
    "plt.legend()\n",
    "plt.title('Prediccion con NHITS (Red Neuronal)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparacion de modelos\n",
    "\n",
    "Comparemos los tres modelos en un mismo grafico y en una tabla de metricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(train.index[-36:], train['pasajeros'][-36:], label='Entrenamiento', color='gray')\n",
    "plt.plot(test.index, test['pasajeros'], label='Real', marker='o', color='black', linewidth=2)\n",
    "plt.plot(test.index, pred_arima, label='ARIMA', marker='s', linestyle='--')\n",
    "plt.plot(test.index, pred_lgb, label='LightGBM', marker='^', linestyle='--')\n",
    "plt.plot(test.index, pred_nhits, label='NHITS', marker='d', linestyle='--')\n",
    "plt.legend()\n",
    "plt.title('Comparacion de modelos')\n",
    "plt.ylabel('Pasajeros (miles)')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nResumen de metricas:\")\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "print(df_resultados.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada enfoque tiene sus ventajas:\n",
    "- **ARIMA**: facil de interpretar, funciona bien con pocas datos, ideal para series con patrones claros\n",
    "- **LightGBM**: muy flexible, permite agregar variables externas facilmente, rapido de entrenar\n",
    "- **NHITS**: puede capturar patrones complejos automaticamente, muy potente con grandes cantidades de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1:\n",
    "\n",
    "Prueba diferentes parametros para ARIMA. Modifica los valores de (p, d, q) y (P, D, Q, 12) y compara los resultados. Puedes probar por ejemplo:\n",
    "- order=(2, 1, 2), seasonal_order=(1, 1, 1, 12)\n",
    "- order=(1, 1, 1), seasonal_order=(2, 1, 2, 12)\n",
    "- order=(0, 1, 1), seasonal_order=(0, 1, 1, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribir aqui la solucion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Solucion Ejercicio 1 {display-mode:\"form\"}\n",
    "\n",
    "parametros = [\n",
    "    ((1, 1, 1), (1, 1, 1, 12)),\n",
    "    ((2, 1, 2), (1, 1, 1, 12)),\n",
    "    ((1, 1, 1), (2, 1, 2, 12)),\n",
    "    ((0, 1, 1), (0, 1, 1, 12)),\n",
    "]\n",
    "\n",
    "for order, seasonal_order in parametros:\n",
    "    model = SARIMAX(train['pasajeros'], order=order, seasonal_order=seasonal_order)\n",
    "    model_fit = model.fit(disp=False)\n",
    "    pred = model_fit.forecast(steps=12)\n",
    "    mae = mean_absolute_error(test['pasajeros'].values, pred.values)\n",
    "    rmse = np.sqrt(mean_squared_error(test['pasajeros'].values, pred.values))\n",
    "    print(f\"ARIMA{order} x {seasonal_order}: MAE={mae:.2f}, RMSE={rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2:\n",
    "\n",
    "Reemplaza LightGBM por [XGBoost](https://xgboost.readthedocs.io/). Instala xgboost con `!pip install xgboost -q` y utiliza `XGBRegressor` con los mismos features que creamos anteriormente. Compara los resultados con LightGBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribir aqui la solucion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Solucion Ejercicio 2 {display-mode:\"form\"}\n",
    "\n",
    "!pip install xgboost -q\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "model_xgb = XGBRegressor(n_estimators=200, learning_rate=0.1, random_state=42, verbosity=0)\n",
    "model_xgb.fit(X_train_lgb, y_train_lgb)\n",
    "pred_xgb = model_xgb.predict(X_test_lgb)\n",
    "\n",
    "evaluar_modelo('XGBoost', y_test_lgb.values, pred_xgb)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(test.index, test['pasajeros'], label='Real', marker='o', color='black')\n",
    "plt.plot(test.index, pred_lgb, label='LightGBM', marker='^', linestyle='--')\n",
    "plt.plot(test.index, pred_xgb, label='XGBoost', marker='s', linestyle='--')\n",
    "plt.legend()\n",
    "plt.title('LightGBM vs XGBoost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fin: [Volver al contenido del curso](https://www.freecodingtour.com/cursos/espanol/datascience/datascience.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
