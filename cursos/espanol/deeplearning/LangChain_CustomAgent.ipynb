{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "93460a56-4979-4e95-8479-b43c3fb8e43c",
      "metadata": {
        "id": "93460a56-4979-4e95-8479-b43c3fb8e43c"
      },
      "source": [
        "# Agents o Assistants\n",
        "\n",
        "Sabemos que los LLMs son grandes cajas negras que interpretan el lenguaje natural y nos pueden dar respuestas tambien en nuestro lenguaje de acuerdo a la informacion que tienen comprimida adentro de acuerdo a su entrenamiento.\n",
        "\n",
        "Que pasa si a estos LLMs ademas les damos herramientas para que puedan obtener informacion actualizada y verificada del mundo real?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e49ef5f-a2a2-4eac-80f7-3b28bfb44369",
      "metadata": {
        "id": "3e49ef5f-a2a2-4eac-80f7-3b28bfb44369"
      },
      "source": [
        "## OpenAI Functions and LangChain Tools\n",
        "\n",
        "Veamos como podemos darles estas herramientas a los LLMs. En OpenAI les llaman functions y en LangChain Tools:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e33017cc-fa5d-4484-b88e-9d88055f0f2b",
      "metadata": {
        "id": "e33017cc-fa5d-4484-b88e-9d88055f0f2b",
        "outputId": "f1763e20-d002-49d1-ac79-1a5507c9feb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/221.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/221.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.4/221.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.1/809.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.1/189.1 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install openai --upgrade --quiet\n",
        "!pip install langchain --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8c905551-8406-4f0e-b937-cbab50a98f4a",
      "metadata": {
        "id": "8c905551-8406-4f0e-b937-cbab50a98f4a"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "api_key=\"INGRESA AQUI TU TOKEN DE OPENAI\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "89c68f13-fd5a-46e2-a445-eb8fb7dffa3b",
      "metadata": {
        "id": "89c68f13-fd5a-46e2-a445-eb8fb7dffa3b",
        "outputId": "678570a0-ae2c-4036-fa94-1fea80d83035",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title [Opcional] cargar el token desde gdrive para que no se vea al dar clases {display-mode:\"form\"}\n",
        "if api_key == \"INGRESA AQUI TU TOKEN DE OPENAI\":\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    with open('drive/MyDrive/Tokens/openai.txt','r') as f:\n",
        "        api_key = f.read()\n",
        "        openai.api_key = api_key"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
        "from langchain.prompts import StringPromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMMathChain\n",
        "from langchain.chains import LLMChain\n",
        "from typing import List, Union\n",
        "from langchain.schema import AgentAction, AgentFinish, OutputParserException\n",
        "import re"
      ],
      "metadata": {
        "id": "AGZpav7k2ZS4"
      },
      "id": "AGZpav7k2ZS4",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define which tools the agent can use to answer user queries\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"math\",\n",
        "        func=LLMMathChain.from_llm(OpenAI(openai_api_key=api_key)),\n",
        "        description=\"util cuando quieres realizar operaciones matematicas\"\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "cAB4eLAA2cMH"
      },
      "id": "cAB4eLAA2cMH",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the base template\n",
        "template = \"\"\"Contesta la siguiente pregunta lo mejor que puedas.\n",
        "Tienes acceso a las siguientes herramientas:\n",
        "{tools}\n",
        "Usa el siguiente formato:\n",
        "Pregunta: la pregunta original de entrada que debes responder\n",
        "Analisis: siempre debes analizar que hacer\n",
        "Accion: la accion a realizar, debe ser una de [{tool_names}]\n",
        "Entrada Accion: la entrada de la accion\n",
        "Observacion: el resultado de la accion\n",
        "Analisis: Ya se la respuesta final\n",
        "Respuesta Final: la respuesta final a la pregunta original de entrada\n",
        "Pregunta: {input}\n",
        "{agent_scratchpad}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "6qJazIwk2IpO"
      },
      "id": "6qJazIwk2IpO",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up a prompt template\n",
        "class CustomPromptTemplate(StringPromptTemplate):\n",
        "    # The template to use\n",
        "    template: str\n",
        "    # The list of tools available\n",
        "    tools: List[Tool]\n",
        "\n",
        "    def format(self, **kwargs) -> str:\n",
        "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
        "        # Format them in a particular way\n",
        "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
        "        thoughts = \"\"\n",
        "        for action, observation in intermediate_steps:\n",
        "            thoughts += action.log\n",
        "            thoughts += f\"\\Observacion: {observation}\\Analisis: \"\n",
        "        # Set the agent_scratchpad variable to that value\n",
        "        kwargs[\"agent_scratchpad\"] = thoughts\n",
        "        # Create a tools variable from the list of tools provided\n",
        "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
        "        # Create a list of tool names for the tools provided\n",
        "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
        "        return self.template.format(**kwargs)"
      ],
      "metadata": {
        "id": "Gry-NeDM2Ir0"
      },
      "id": "Gry-NeDM2Ir0",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = CustomPromptTemplate(\n",
        "    template=template,\n",
        "    tools=tools,\n",
        "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
        "    # This includes the `intermediate_steps` variable because that is needed\n",
        "    input_variables=[\"input\", \"intermediate_steps\"]\n",
        ")"
      ],
      "metadata": {
        "id": "kSGQLXtr2IuS"
      },
      "id": "kSGQLXtr2IuS",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomOutputParser(AgentOutputParser):\n",
        "\n",
        "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
        "        # Check if agent should finish\n",
        "        if \"Respuesta Final:\" in llm_output:\n",
        "            return AgentFinish(\n",
        "                # Return values is generally always a dictionary with a single `output` key\n",
        "                # It is not recommended to try anything else at the moment :)\n",
        "                return_values={\"output\": llm_output.split(\"Respuesta Final:\")[-1].strip()},\n",
        "                log=llm_output,\n",
        "            )\n",
        "        # Parse out the action and action input\n",
        "        regex = r\"Accion\\s*\\d*\\s*:(.*?)\\nEntrada\\s*\\d*\\s*Accion\\s*\\d*\\s*:[\\s]*(.*)\"\n",
        "        match = re.search(regex, llm_output, re.DOTALL)\n",
        "        if not match:\n",
        "            raise OutputParserException(f\"Could not parse LLM output: `{llm_output}`\")\n",
        "        action = match.group(1).strip()\n",
        "        action_input = match.group(2)\n",
        "        # Return the action and action input\n",
        "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)"
      ],
      "metadata": {
        "id": "qLBi52eU2IxE"
      },
      "id": "qLBi52eU2IxE",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_parser = CustomOutputParser()"
      ],
      "metadata": {
        "id": "TSvCND0y2Izj"
      },
      "id": "TSvCND0y2Izj",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(openai_api_key=api_key, temperature=0)"
      ],
      "metadata": {
        "id": "LkF5Ts-P2I1o"
      },
      "id": "LkF5Ts-P2I1o",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM chain consisting of the LLM and a prompt\n",
        "llm_chain = LLMChain(llm=llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "DUAszMyK3sdH"
      },
      "id": "DUAszMyK3sdH",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tool_names = [tool.name for tool in tools]\n",
        "agent = LLMSingleActionAgent(\n",
        "    llm_chain=llm_chain,\n",
        "    output_parser=output_parser,\n",
        "    stop=[\"\\nObservacion:\"],\n",
        "    allowed_tools=tool_names\n",
        ")"
      ],
      "metadata": {
        "id": "Vhspp_7L2I6C"
      },
      "id": "Vhspp_7L2I6C",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)"
      ],
      "metadata": {
        "id": "-pznd2ZE3vGd"
      },
      "id": "-pznd2ZE3vGd",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.run(\"Cuantos dias tienen la suma de los dias de los siguientes dos meses febrero del 2005 y agosto del 2017?\")"
      ],
      "metadata": {
        "id": "BcxdrVzW3vJA",
        "outputId": "a94a4452-ee77-42f4-bac2-b1ff2cf27528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "id": "BcxdrVzW3vJA",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAnalisis: Para responder esta pregunta, necesitamos calcular el numero de dias de cada mes.\n",
            "Accion: math\n",
            "Entrada Accion: (31 + 31) + (31 + 30 + 31 + 30 + 31 + 31 + 30 + 31)\u001b[0m\n",
            "\n",
            "Observacion:\u001b[36;1m\u001b[1;3m{'question': '(31 + 31) + (31 + 30 + 31 + 30 + 31 + 31 + 30 + 31)', 'answer': 'Answer: 307'}\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAhora tenemos la respuesta de 307 dias.\n",
            "Respuesta Final: La suma de los dias de los dos meses es de 307 dias.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'La suma de los dias de los dos meses es de 307 dias.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q7OeYDTl3vL2"
      },
      "id": "q7OeYDTl3vL2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yhFtgVAz3vN8"
      },
      "id": "yhFtgVAz3vN8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HHsWYIz53vQP"
      },
      "id": "HHsWYIz53vQP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A2JWrhxP2I8s"
      },
      "id": "A2JWrhxP2I8s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M6YWZXUs2I_M"
      },
      "id": "M6YWZXUs2I_M",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}