{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93460a56-4979-4e95-8479-b43c3fb8e43c",
   "metadata": {},
   "source": [
    "# Agents o Assistants\n",
    "\n",
    "Sabemos que los LLMs son grandes cajas negras que interpretan el lenguaje natural y nos pueden dar respuestas tambien en nuestro lenguaje de acuerdo a la informacion que tienen comprimida adentro de acuerdo a su entrenamiento.\n",
    "\n",
    "Que pasa si a estos LLMs ademas les damos herramientas para que puedan obtener informacion actualizada y verificada del mundo real?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e49ef5f-a2a2-4eac-80f7-3b28bfb44369",
   "metadata": {},
   "source": [
    "## OpenAI Functions and LangChain Tools\n",
    "\n",
    "Veamos como podemos darles estas herramientas a los LLMs. En OpenAI les llaman functions y en LangChain Tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33017cc-fa5d-4484-b88e-9d88055f0f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai --upgrade --quiet\n",
    "!pip install langchain --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c905551-8406-4f0e-b937-cbab50a98f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "api_key=\"INGRESA AQUI TU TOKEN DE OPENAI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c68f13-fd5a-46e2-a445-eb8fb7dffa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title [Opcional] cargar el token desde gdrive para que no se vea al dar clases {display-mode:\"form\"}\n",
    "if api_key == \"INGRESA AQUI TU TOKEN DE OPENAI\":\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    with open('drive/MyDrive/Tokens/openai.txt','r') as f:\n",
    "        token = f.read()\n",
    "        openai.api_key = token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51422385-9e51-43ac-b625-c42ba963eae7",
   "metadata": {},
   "source": [
    "### OpenAI functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f2e9f5-17ab-4aee-99e4-c7911a2b5736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"72\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": [\"sunny\", \"windy\"],\n",
    "    }\n",
    "    return json.dumps(weather_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6c1144-c0c5-41bd-b24f-28f00072358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1162d620-4d8c-456a-80d6-d986b1893ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather like in Boston?\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd2da8b-e2e8-4f29-8372-ff3ca30cf7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    "    functions=functions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0874effc-5616-4f30-98a0-4e99b0cdb24c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creando nuestra propia tool en LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f70e9fa-dc04-4a1e-8f4a-61e142a11ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a260840a-87a5-4363-9000-158c008f3a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def time(text: str) -> str:\n",
    "    \"\"\"Returns todays date, use this for any \\\n",
    "    questions related to knowing todays date. \\\n",
    "    The input should always be an empty string, \\\n",
    "    and this function will always return todays \\\n",
    "    date - any date mathmatics should occur \\\n",
    "    outside this function.\"\"\"\n",
    "    return str(date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8dfc4e-8415-4a4b-86bd-3f75f0ceb7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    tools + [time], \n",
    "    llm, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c019de52-6a7d-4a87-aa0f-d45616ef5ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    result = agent(\"whats the date today?\") \n",
    "except: \n",
    "    print(\"exception on external access\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61b9f67-0e88-4844-92ee-6867ae99e15c",
   "metadata": {},
   "source": [
    "## LangChain Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdfca4b-ea62-4e8a-b420-c35682607e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U wikipedia\n",
    "!pip install openai --upgrade --quiet\n",
    "!pip install langchain --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ce5c4c-87be-4aa4-b342-2a56917a93fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools, initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a210fe53-c99d-4b48-a2de-87cbf986c310",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(openai_api_key=token, temperature=0.0, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dde94dd-6b77-41e5-8c8d-1db6e24c5831",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"llm-math\",\"wikipedia\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86d4f9d-2ea8-441e-a9fb-63430ab01ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent= initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb7cd7f-111c-443d-a706-a5076b21aad3",
   "metadata": {},
   "source": [
    "#### Agente de matematica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a9dad8-af57-4df7-96c8-41c9aaf5df8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent(\"What is the 25% of 300?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4e422d-0d94-4022-bda1-2c25ed1283f6",
   "metadata": {},
   "source": [
    "#### Agente de wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb695944-47fe-4f7e-9fd4-db7341d70281",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Tom M. Mitchell is an American computer scientist \\\n",
    "and the Founders University Professor at Carnegie Mellon University (CMU)\\\n",
    "what book did he write?\"\n",
    "result = agent(question) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8abdda-a8e4-4b23-a335-cd095720ccd5",
   "metadata": {},
   "source": [
    "#### Agente de python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e455dc3a-1686-49a0-8f3c-a8a0448f0113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.python import PythonREPL\n",
    "\n",
    "agent = create_python_agent(\n",
    "    llm,\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d672d2fd-496a-410a-935a-dd0bbdd9624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_list = [[\"Harrison\", \"Chase\"], \n",
    "                 [\"Lang\", \"Chain\"],\n",
    "                 [\"Dolly\", \"Too\"],\n",
    "                 [\"Elle\", \"Elem\"], \n",
    "                 [\"Geoff\",\"Fusion\"], \n",
    "                 [\"Trance\",\"Former\"],\n",
    "                 [\"Jen\",\"Ayai\"]\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb3f88e-2f26-4c82-846d-92aa7694da8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(f\"\"\"Sort these customers by \\\n",
    "last name and then first name \\\n",
    "and print the output: {customer_list}\"\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc29941-ce01-4ff8-9bea-39a9ebf4c024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug=True\n",
    "agent.run(f\"\"\"Sort these customers by \\\n",
    "last name and then first name \\\n",
    "and print the output: {customer_list}\"\"\") \n",
    "langchain.debug=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27623d45-ddc2-4309-9515-037c3b44e8e2",
   "metadata": {},
   "source": [
    "Mas tipos de agentes: https://python.langchain.com/docs/modules/agents/agent_types/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baacaa93-3a2e-4461-80bf-b56de4273751",
   "metadata": {},
   "source": [
    "## Crear nuestro propio Agente\n",
    "\n",
    "- https://blog.langchain.dev/custom-agents/\n",
    "- https://python.langchain.com/docs/modules/agents/how_to/custom_agent\n",
    "- https://artificialcorner.com/how-to-build-tool-using-agents-with-langchain-d9fa9674b6c7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2162b9d1-aa89-4f66-8556-ba62c9a67185",
   "metadata": {},
   "source": [
    "## Referencias:\n",
    "Esta unidad esta basada en el [curso de Andrew Ng de Deeplearning.ai](https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cb124c-1024-4e33-80b6-b57bd4eeb76b",
   "metadata": {},
   "source": [
    "# Fin: [Volver al contenido del curso](https://www.freecodingtour.com/cursos/espanol/deeplearning/deeplearning.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
