{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93460a56-4979-4e95-8479-b43c3fb8e43c",
   "metadata": {},
   "source": [
    "# Assistants\n",
    "\n",
    "Sabemos que los LLMs son grandes cajas negras que interpretan el lenguaje natural y nos pueden dar respuestas tambien en nuestro lenguaje de acuerdo a la informacion que tienen comprimida adentro de acuerdo a su entrenamiento.\n",
    "\n",
    "Que pasa si a estos LLMs ademas les damos herramientas para que puedan obtener informacion actualizada y verificada del mundo real?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e49ef5f-a2a2-4eac-80f7-3b28bfb44369",
   "metadata": {},
   "source": [
    "## OpenAI Functions\n",
    "\n",
    "Veamos como podemos darles estas herramientas a los LLMs. En OpenAI les llaman functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33017cc-fa5d-4484-b88e-9d88055f0f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c905551-8406-4f0e-b937-cbab50a98f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "api_key=\"INGRESA AQUI TU TOKEN DE OPENAI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c68f13-fd5a-46e2-a445-eb8fb7dffa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title [Opcional] cargar el token desde colab para que no se vea al dar clases {display-mode:\"form\"}\n",
    "if api_key == \"INGRESA AQUI TU TOKEN DE OPENAI\":\n",
    "    from google.colab import userdata\n",
    "    api_key = userdata.get('OPENAI_TOKEN')\n",
    "    openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51422385-9e51-43ac-b625-c42ba963eae7",
   "metadata": {},
   "source": [
    "### OpenAI tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f2e9f5-17ab-4aee-99e4-c7911a2b5736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def get_current_weather(location, unit=\"celcius\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"26\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": [\"sunny\", \"windy\"],\n",
    "    }\n",
    "    return json.dumps(weather_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6c1144-c0c5-41bd-b24f-28f00072358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a tool\n",
    "tools = [\n",
    "  {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"get_current_weather\",\n",
    "      \"description\": \"Get the current weather in a given location\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "          },\n",
    "          \"unit\": {\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\"location\"]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1162d620-4d8c-456a-80d6-d986b1893ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather like in Boston?\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd2da8b-e2e8-4f29-8372-ff3ca30cf7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    "    max_tokens=100,\n",
    "    temperature=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e4f49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be84c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Function to call:\",response.choices[0].message.tool_calls[0].function.name)\n",
    "print(\"Function arguments:\",response.choices[0].message.tool_calls[0].function.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7089822",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29303f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: determine if the response from the model includes a tool call.   \n",
    "tool_calls = response.choices[0].message.tool_calls\n",
    "if tool_calls:\n",
    "    # If true the model will return the name of the tool / function to call and the argument(s)  \n",
    "    tool_call_id = tool_calls[0].id\n",
    "    tool_function_name = tool_calls[0].function.name\n",
    "    tool_function_arguments = eval(tool_calls[0].function.arguments)\n",
    "    \n",
    "    # Step 3: Call the function and retrieve results. Append the results to the messages list.      \n",
    "    if tool_function_name == 'get_current_weather':\n",
    "        results = get_current_weather(**tool_function_arguments)\n",
    "        \n",
    "        messages.append({\n",
    "            \"role\":\"tool\", \n",
    "            \"tool_call_id\":tool_call_id, \n",
    "            \"name\": tool_function_name, \n",
    "            \"content\":results\n",
    "        })\n",
    "        \n",
    "        # Step 4: Invoke the chat completions API with the function response appended to the messages list\n",
    "        # Note that messages with role 'tool' must be a response to a preceding message with 'tool_calls'\n",
    "        model_response_with_function_call = openai.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=messages,\n",
    "        )  # get a new response from the model where it can see the function response\n",
    "        print(model_response_with_function_call.choices[0].message.content)\n",
    "    else: \n",
    "        print(f\"Error: function {tool_function_name} does not exist\")\n",
    "else: \n",
    "    # Model did not identify a function to call, result can be returned to the user \n",
    "    print(response.content) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ac13c9",
   "metadata": {},
   "source": [
    "## Referencias:\n",
    "\n",
    "- https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cb124c-1024-4e33-80b6-b57bd4eeb76b",
   "metadata": {},
   "source": [
    "# Fin: [Volver al contenido del curso](https://www.freecodingtour.com/cursos/espanol/deeplearning/deeplearning.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
