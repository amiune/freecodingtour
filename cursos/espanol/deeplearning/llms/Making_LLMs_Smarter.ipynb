{"cells":[{"cell_type":"markdown","id":"c08833d7-54cd-495e-8eb8-1c60721d5d1d","metadata":{"id":"c08833d7-54cd-495e-8eb8-1c60721d5d1d"},"source":["# Haciendo mas inteligentes a las Redes Neuronales (LLMs)\n","\n","Aqui veremos como hacer mas inteligentes a las redes neuronales solucionando algunos de los problemas vistos en las unidades anteriores.\n","\n"]},{"cell_type":"code","execution_count":null,"id":"49f7e79f-64f6-4880-af61-581a28a8086a","metadata":{"id":"49f7e79f-64f6-4880-af61-581a28a8086a"},"outputs":[],"source":["!pip install openai --upgrade --quiet\n","from openai import OpenAI\n","##########################################\n","api_key=\"INGRESA AQUI TU TOKEN DE OPENAI\"\n","##########################################\n","if api_key[25:] == \"OPENAI\":\n","    from google.colab import userdata\n","    api_key = userdata.get('OPENAI_TOKEN')\n","# defaults to os.environ.get(\"OPENAI_API_KEY\")\n","client = OpenAI(api_key=api_key)"]},{"cell_type":"code","execution_count":null,"id":"1ea37c54-3075-435f-a48f-48f8fd1226c2","metadata":{"id":"1ea37c54-3075-435f-a48f-48f8fd1226c2"},"outputs":[],"source":["def generar_texto(prompt, model=\"gpt-4o\"):\n","    messages = [{\"role\": \"user\", \"content\": prompt}]\n","    response = client.chat.completions.create(\n","        model=model,\n","        messages=messages,\n","        temperature=0, # aleatoriedad de las respuestas del modelo\n","    )\n","    return response.choices[0].message.content"]},{"cell_type":"code","source":["# Opcional si no tienes cuenta en OpenAI\n","# Puedes utilizar un modelo pequeño con huggingface pipelines\n","# Solo quita las comilla triples al siguiente codigo:\n","\n","\"\"\"\n","from transformers import pipeline\n","generator = pipeline('text-generation', model = 'Qwen/Qwen2-0.5B-Instruct')\n","def generar_texto(prompt):\n","    return generator(prompt, max_length = 30, num_return_sequences=1)[0][\"generated_text\"]\n","\"\"\""],"metadata":{"id":"Y-QN3GYHc6rG"},"id":"Y-QN3GYHc6rG","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"2aae4ecf-63c5-4bcc-b95b-a985ffdcfe18","metadata":{"id":"2aae4ecf-63c5-4bcc-b95b-a985ffdcfe18"},"outputs":[],"source":["generar_texto(\"Hola\")"]},{"cell_type":"code","execution_count":null,"id":"bc7230bb-16d4-49c9-a220-058e1d1b1e4e","metadata":{"id":"bc7230bb-16d4-49c9-a220-058e1d1b1e4e"},"outputs":[],"source":["generar_texto(\"En que año estamos?\")"]},{"cell_type":"code","execution_count":null,"id":"8d00b174-e6d6-48ee-a6f8-435cbdf9cb2d","metadata":{"id":"8d00b174-e6d6-48ee-a6f8-435cbdf9cb2d"},"outputs":[],"source":["generar_texto(\"Mi nombre es Hernan\")"]},{"cell_type":"code","execution_count":null,"id":"b5ce3674-5e24-410d-bbad-c5facd02eb49","metadata":{"id":"b5ce3674-5e24-410d-bbad-c5facd02eb49"},"outputs":[],"source":["generar_texto(\"Cual es mi nombre?\")"]},{"cell_type":"markdown","source":["## Resolviendo el problema de la Memoria\n","\n","Como hemos visto la red neuronal no tiene memoria solo recibe una entrada y de acuerdo a esa entrada genera un texto de salida. No recuerda entradas anteriores que le hayamos enviado. Para solucionar ese problema debemos nosotros ir guardando todo el historial de entradas y salidas que van ocurriendo en la conversacion y pasarle todo el historial en nuevas llamadas."],"metadata":{"id":"inreDehUdjuB"},"id":"inreDehUdjuB"},{"cell_type":"markdown","source":["### Ejercicio 1:\n","\n","Escribe un codigo en python para ayudar a la red neuronal a tener memoria.\n","\n","*Ayuda:*\n","\n","```python\n","historial = \"\"\n","prompt = \"Hola como estas? Mi nombre es Hernan\"\n","generar_texto(prompt)\n","historial = historial + prompt\n","...\n","```"],"metadata":{"id":"UQV5vjVte3HK"},"id":"UQV5vjVte3HK"},{"cell_type":"code","source":["# Escribir aqui la solucion\n","\n","\n"],"metadata":{"id":"ZTAPBW70e3h2"},"id":"ZTAPBW70e3h2","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Solucion Ejercicio 1 {display-mode:\"form\"}\n","\n","historial = \"\"\n","\n","prompt = \"Mi nombre es Hernan\"\n","response = generar_texto(historial + \" \" + prompt)\n","print(\"Respuesta 1:\", response)\n","historial += f\"User: {prompt}\\nBot: {response}\\n\"\n","\n","prompt = \"Cual es mi nombre?\"\n","response = generar_texto(historial + \" \" + prompt)\n","print(\"Respuesta 2:\", response)\n","historial += f\"User: {prompt}\\nBot: {response}\\n\"\n","\n","print(\"Historial:\", historial)"],"metadata":{"id":"s2SQb7VAzRtG"},"id":"s2SQb7VAzRtG","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Resolviendo el problema del año\n","\n","Como hemos visto la red neuronal ha sido entrenada y puede contestar de acuerdo a la informacion que ha sido almacenada en sus pesos (parametros w). Toda la informacion nueva que surja luego de su entrenamiento es informacion a la que la red neuronal no puede acceder a menos que la ayudemos."],"metadata":{"id":"IMaCjcAqT4Cu"},"id":"IMaCjcAqT4Cu"},{"cell_type":"markdown","source":["### Ejercicio 2:\n","\n","Escribe un codigo en python para ayudar a la red neuronal a saber que año es si alguien le pregunta por el año.\n","\n","*Ayuda 1:*\n","\n","```python\n","def generar_texto2(prompt):\n","    if prompt contiene una pregunta sobre en que año estamos:\n","       return datetime.now().year\n","    else:\n","       return generar_texto(prompt)\n","```"],"metadata":{"id":"VNql7UQEUTXV"},"id":"VNql7UQEUTXV"},{"cell_type":"code","source":["# Escribir aqui la solucion\n","\n","\n"],"metadata":{"id":"AaEaN04SU1ar"},"id":"AaEaN04SU1ar","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Ayuda 2 Ejercicio 2 {display-mode:\"form\"}\n","\n","from datetime import datetime\n","def generar_texto2(prompt):\n","    if prompt == \"En que año estamos?\":\n","       return datetime.now().year\n","    else:\n","       return generar_texto(prompt)\n","\n","print(generar_texto2(\"En que año estamos?\"))\n","print(generar_texto2(\"En que año nos encontramos?\"))"],"metadata":{"id":"OM0jZp_ZrQAo"},"id":"OM0jZp_ZrQAo","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Solucion Ejercicio 2 {display-mode:\"form\"}\n","\n","from datetime import datetime\n","def generar_texto3(prompt):\n","\n","    new_prompt = f\"\"\"Define si la pregunta del final es sobre en que año estamos.\n","    Responde solo si o no con minusculas y sin agregar acentos ni signos de puntuacion, solo usa dos letras.\n","\n","    Pregunta:\n","    {prompt}\n","\n","    Tu respuesta:\n","    \"\"\"\n","\n","    pregunta_el_anio = generar_texto(new_prompt)\n","\n","    print(pregunta_el_anio)\n","\n","    if pregunta_el_anio == \"si\":\n","       return datetime.now().year\n","    else:\n","       return generar_texto(prompt)\n","\n","print(generar_texto3(\"En que año estamos?\"))\n","print(generar_texto3(\"En que año nos encontramos?\"))\n","print(generar_texto3(\"Cuantos dedos tiene una mano?\"))"],"metadata":{"id":"uek4ki0VrQIZ"},"id":"uek4ki0VrQIZ","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Contestar a partir de informacion de un pdf nuestro\n","\n","Esta tecnica se llama Retrieval Augmented Generation y se conoce como RAG.\n","\n","Utilizamos [pypdf2](https://pypdf2.readthedocs.io/en/3.x/) para leer el siguiente pdf sobre delfines:\n","- https://www.amc.edu.mx/revistaciencia/images/revista/70_3/PDF/10_70_3_1156_Delfin_L.pdf\n"],"metadata":{"id":"v2wdEK6vWXSF"},"id":"v2wdEK6vWXSF"},{"cell_type":"code","source":["!pip install PyPDF2 -U -q"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hpDcHg6dWc0P","executionInfo":{"status":"ok","timestamp":1721324163056,"user_tz":-120,"elapsed":10405,"user":{"displayName":"Hernán Amiune","userId":"11385806853064071251"}},"outputId":"c1fdbd5d-ba2d-40ce-d2dc-739430aeb937"},"id":"hpDcHg6dWc0P","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/232.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import requests\n","from PyPDF2 import PdfReader\n","\n","url = \"https://www.amc.edu.mx/revistaciencia/images/revista/70_3/PDF/10_70_3_1156_Delfin_L.pdf\"\n","response = requests.get(url)\n","\n","with open(\"delfines.pdf\", \"wb\") as f:\n","  f.write(response.content)\n","\n","reader = PdfReader(\"delfines.pdf\")\n","page = reader.pages[0]\n","texto = page.extract_text()\n","print(texto[0:500])"],"metadata":{"id":"BHmCyQ4pWuIG"},"id":"BHmCyQ4pWuIG","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generar_texto4(prompt):\n","\n","    new_prompt = f\"\"\"Responde la pregunta del final utlizando la siguiente informacion:\n","    {texto}\n","\n","    Pregunta a responder:\n","    {prompt}\n","\n","    Tu respuesta:\n","    \"\"\"\n","\n","    return generar_texto(new_prompt)"],"metadata":{"id":"_TlKGxsYWuKZ"},"id":"_TlKGxsYWuKZ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["generar_texto4(\"Que porcentaje de diversidad de delfines viven en Mexico?\")"],"metadata":{"id":"8SOqzHhMWuMe"},"id":"8SOqzHhMWuMe","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Ejercicio 3:\n","\n","Utiliza esta tecnica para preguntarle al chat con un documento propio."],"metadata":{"id":"MNu4n4REfgji"},"id":"MNu4n4REfgji"},{"cell_type":"code","source":["# Escribir aqui la solucion\n","\n","\n"],"metadata":{"id":"eL-fzJl3fgrb"},"id":"eL-fzJl3fgrb","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Hacer que un LLM pueda buscar informacion en Internet\n","\n","---\n","\n"],"metadata":{"id":"W4oc-kfOTkKe"},"id":"W4oc-kfOTkKe"},{"cell_type":"code","source":["!pip install exa-py -U -q"],"metadata":{"id":"PactsWKNtqe2"},"id":"PactsWKNtqe2","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from exa_py import Exa\n","from google.colab import userdata\n","\n","exa = Exa(api_key=userdata.get('EXA_TOKEN'))\n","\n","#https://docs.exa.ai/reference/search\n","result = exa.search_and_contents(\n","  \"campeon eurocopa 2024\",\n","  type=\"neural\",\n","  use_autoprompt=True,\n","  num_results=10,\n","  text=True\n",")"],"metadata":{"id":"YZ7KAotq6Mb1"},"id":"YZ7KAotq6Mb1","execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i, r in enumerate(result.results):\n","    print(i, r.title, r.url)"],"metadata":{"id":"nH9tBS62uXZf"},"id":"nH9tBS62uXZf","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generar_texto5(prompt):\n","\n","    respuesta_final = \"\"\n","\n","    new_prompt = f\"\"\"Trata de responder la pregunta entre parentesis.\n","    Si no sabes como responder entonces solamente responde \"No se\" y no agregues nada mas.\n","    ({prompt})\n","    \"\"\"\n","\n","    sabe_responder = generar_texto(new_prompt)\n","\n","    print(\"Primera respuesta:\", sabe_responder)\n","\n","    if sabe_responder == \"No se\":\n","\n","        result = exa.search_and_contents(\n","          prompt,\n","          type=\"keyword\",\n","          use_autoprompt=True,\n","          num_results=1,\n","          text=True\n","        )\n","\n","        print(\"Respuesta del buscador:\", result.results[0].text[0:1000], \"....... (este texto fue truncado)\")\n","\n","        new_prompt = f\"\"\"Responde la pregunta del final utlizando la siguiente informacion:\n","        {result.results[0].text[0:16000]}\n","\n","        Pregunta a responder:\n","        {prompt}\n","\n","        Tu respuesta:\n","        \"\"\"\n","\n","        respuesta_final = generar_texto(new_prompt)\n","\n","\n","    else:\n","        respuesta_final = generar_texto(prompt)\n","\n","    print(\"Respuesta final:\", respuesta_final)\n","    return respuesta_final"],"metadata":{"id":"PgUB1WQK6MeC"},"id":"PgUB1WQK6MeC","execution_count":null,"outputs":[]},{"cell_type":"code","source":["generar_texto5(\"Quien gano la eurocopa 2024?\");"],"metadata":{"id":"NkHDHRieyfVS"},"id":"NkHDHRieyfVS","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Crear nuestra propia interfaz para chatear con nuestro LLM\n","\n","- https://www.gradio.app/guides/creating-a-chatbot-fast#customizing-your-chatbot"],"metadata":{"id":"Br51aZ_1Tr8Q"},"id":"Br51aZ_1Tr8Q"},{"cell_type":"code","source":["!pip install --upgrade gradio -q"],"metadata":{"id":"LoQOoIpH6MQP"},"id":"LoQOoIpH6MQP","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gradio as gr\n","\n","def mi_funcion_de_generacion_de_texto(message, history):\n","  \"\"\"\n","  message: a str representing the user's input.\n","  history: a list of list representing the conversations up until that point.\n","  Each inner list consists of two str representing a pair: [user input, bot response].\n","  \"\"\"\n","  return generar_texto(message)\n","\n","gr.ChatInterface(mi_funcion_de_generacion_de_texto).launch()"],"metadata":{"id":"uFJLyHVf9WhX"},"id":"uFJLyHVf9WhX","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gradio as gr\n","\n","def convert_history_to_text(history):\n","    text = \"\"\n","    for pair in history:\n","        user_message, bot_message = pair\n","        text += f\"User: {user_message}\\n\"\n","        text += f\"Bot: {bot_message}\\n\"\n","\n","    return text\n","\n","def mi_funcion_de_generacion_de_texto(message, history):\n","  \"\"\"\n","  message: a str representing the user's input.\n","  history: a list of list representing the conversations up until that point. Each inner list consists of two str representing a pair: [user input, bot response].\n","  \"\"\"\n","  prompt = convert_history_to_text(history) + f\"User: {message}\\nBot:\"\n","\n","\n","\n","  return generar_texto(prompt)\n","\n","gr.ChatInterface(\n","    mi_funcion_de_generacion_de_texto,\n","    chatbot=gr.Chatbot(height=500),\n","    textbox=gr.Textbox(placeholder=\"Hazme una pregunta\", container=False, scale=7),\n","    title=\"Mi Chat\",\n","    #description=\"Ask Yes Man any question\",\n","    theme=\"soft\",\n","    #examples=[\"Hello\", \"Am I cool?\", \"Are tomatoes vegetables?\"],\n","    cache_examples=True,\n","    retry_btn=None,\n","    undo_btn=None,\n","    clear_btn=None,\n",").launch()"],"metadata":{"id":"ZLmItTxt6MZa"},"id":"ZLmItTxt6MZa","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Ejercicio 4:\n","\n","Crea tu propio chatbot y agregale alguna de las funcionalidades vistas anteriormente para hacerlo mas inteligente."],"metadata":{"id":"bHwrbg1qgY7b"},"id":"bHwrbg1qgY7b"},{"cell_type":"code","source":["# Escribir aqui la solucion\n","\n","\n"],"metadata":{"id":"Jx5hfD5-gk25"},"id":"Jx5hfD5-gk25","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Referencias:\n","\n","- https://docs.exa.ai/reference/getting-started-with-python\n","- https://colab.research.google.com/drive/1Aj6bBptSHWxZO7GVG2RoWtQSEkpabuaF\n"],"metadata":{"id":"ahIDnDSawvZq"},"id":"ahIDnDSawvZq"}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"colab":{"provenance":[{"file_id":"https://github.com/amiune/freecodingtour/blob/main/cursos/espanol/deeplearning/llms/OpenAI_Prompting.ipynb","timestamp":1721241026511}]}},"nbformat":4,"nbformat_minor":5}