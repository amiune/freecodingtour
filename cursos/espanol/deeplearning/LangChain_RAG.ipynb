{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c018e8a-e50c-4d68-8b1d-8e6253f08c57",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c25d18-3918-4871-9de1-26d10c067b03",
   "metadata": {},
   "source": [
    "RAG nos permite darle documentos o bases de datos a un LLM para que este pueda obtener informacion desde alli y responder preguntas de acuerdo a los datos que puede extraer de esos documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29a42aa-2930-4b1b-a547-0adac03c597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai --upgrade --quiet\n",
    "!pip install langchain --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e4957e-b641-4f74-966d-3663ac55b445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Cargar token desde google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "with open('drive/MyDrive/Tokens/openai.txt','r') as f:\n",
    "    token = f.read()\n",
    "    openai.api_key = token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dd4a2e-d0f7-4c94-b32c-bf22a31e03a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "chat = ChatOpenAI(openai_api_key=token, temperature=0.0, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a832dc1-43e7-4ce0-81bb-01b2b9be840e",
   "metadata": {},
   "source": [
    "Como habiamos visto anteriormente en el curso podemos crear vectores a partir de texto o imagenes y luego los podemos comparar para ver cuales son mas similares. LangChain nos permite hacer esto de forma muy sencilla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc17a98-670c-497b-92a3-734854e6392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DocArrayInMemorySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e84596-984d-46cc-a30c-9236c7cabde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "    [\"harrison worked at kensho\", \"bears like to eat honey\"],\n",
    "    embedding=OpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2218206-be30-4afe-92c7-f227815bc179",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.get_relevant_documents(\"where did harrison work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22a5c31-0fb7-4741-995e-bfdd1d4226f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.get_relevant_documents(\"what do bears like to eat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de42882e-4255-4644-a316-5e732d3200cb",
   "metadata": {},
   "source": [
    "Podemos incorporar todo esto a un chat de forma sencilla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffa11ca-6cff-4890-8290-fc47867eb1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c885de1c-4da1-4ba4-9be5-0479997bcff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableMap({\n",
    "    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77332b42-cf2e-485e-9d15-83558d377c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"question\": \"where did harrison work?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a893488-896c-492d-8784-a47ea3f4507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca038e5-9a43-4ebe-8975-396ff78a0054",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"tell me a short joke about {topic}\"\n",
    ")\n",
    "model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb83e0a-01b2-4495-9878-cbd8403c0fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcd16ef-4493-4189-b497-7add17dee7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0854b159-1ffd-43fe-adfd-511235682d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableMap({\n",
    "    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "}) | prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b51619-5808-4b22-8bbb-d9b328e540b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"question\": \"where did harrison work?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cb9181-87ad-48cf-8eee-26100b71c4ee",
   "metadata": {},
   "source": [
    "Podemos utilizar base de datos mas potentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a0635b-c448-405e-ba70-acf3ebe89d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lark --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1706c05-72eb-463d-9541-d9b0886852ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "persist_directory = 'docs/chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41461d4f-ef2c-4de0-a9ea-5903d92b22a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd79b565-6bfb-427f-a3a0-fc8f07ae4b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4066c5fe-4d1a-4e3b-8a0f-47aa5c54831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"\"\"The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).\"\"\",\n",
    "    \"\"\"A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\"\"\",\n",
    "    \"\"\"A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.\"\"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e29b6e-bac6-469f-990e-b12abc34001a",
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldb = Chroma.from_texts(texts, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fc0bba-cfe0-403b-93f5-250af5eca6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Tell me about all-white mushrooms with large fruiting bodies\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e47e974-5e8f-4b84-b4bb-9c4331a5b34f",
   "metadata": {},
   "source": [
    "Buscar similares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027e18f8-bcea-4991-8708-fd4d9824138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldb.similarity_search(question, k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940b7c4c-a9a5-4f56-8c80-eb8ef6719d21",
   "metadata": {},
   "source": [
    "Buscar similares pero con diversidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88a2e6f-b60d-4d98-9bc7-d8270d462cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldb.max_marginal_relevance_search(question,k=2, fetch_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d84bd6e-353d-4f96-a008-229dc9afd977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532fb955-6518-485a-a8c7-95aa6ed45151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a857c9-aec5-483a-b066-3545dc01dd19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80886959-9793-4c2d-a3ce-46f7504772aa",
   "metadata": {},
   "source": [
    "## Referencias:\n",
    "Esta unidad es un resumen traducido con algunas modificaciones del [curso de Andrew Ng de Deeplearning.ai](https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/)\n",
    "\n",
    "Meta, articulo original sobre RAG: https://ai.meta.com/blog/retrieval-augmented-generation-streamlining-the-creation-of-intelligent-natural-language-processing-models/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a09c23-d790-49d1-99b1-c72c0650545e",
   "metadata": {},
   "source": [
    "# Fin: [Volver al contenido del curso](https://www.freecodingtour.com/cursos/espanol/deeplearning/deeplearning.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
