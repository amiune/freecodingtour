{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d96fbc4-9c12-4f05-a5b5-d7af61a5dcb3",
   "metadata": {},
   "source": [
    "# LangChain Chains\n",
    "\n",
    "Aqui nos enfocaremos en las cadenas o Chains que son muy importantes en la libreria LangChain y por ello estan en su nombre.\n",
    "\n",
    "Las Chains nos permiten encadenar la salida de una consulta a un LLM con la entrada a otra consulta y asi conseguir mejores resultados y mas complejos.\n",
    "\n",
    "Una cadena se compone de un modelo,un prompt de entrada y su respectiva salida. Veamos algunos ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06e207f-26bb-413f-8dbf-821936f06456",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai --upgrade --quiet\n",
    "!pip install langchain --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bc6cd7-9903-424a-8359-605dc5f5b318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "api_key=\"INGRESA AQUI TU TOKEN DE OPENAI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212dba5b-b078-48b6-a98d-dad7a772eb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title [Opcional] cargar el token desde gdrive para que no se vea al dar clases {display-mode:\"form\"}\n",
    "if api_key == \"INGRESA AQUI TU TOKEN DE OPENAI\":\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    with open('drive/MyDrive/Tokens/openai.txt','r') as f:\n",
    "        token = f.read()\n",
    "        openai.api_key = token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c22929-e0f5-4bce-9c44-6d834702d583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba0834e-cf41-4881-a5a2-09569cfcc714",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(openai_api_key=token, temperature=0.0, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d89f55-913a-4a1c-8f0e-8f204ee4e59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c205014-6c1e-48b9-abc2-bc2de318383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fb4a34-df45-4b08-b5cc-0a0340569503",
   "metadata": {},
   "outputs": [],
   "source": [
    "product = \"Queen Size Sheet Set\"\n",
    "chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da28c4e-5e52-4dd9-a0f0-8e799da56660",
   "metadata": {},
   "source": [
    "## Simple Sequential Chain\n",
    "\n",
    "En este ejemplo como su nombre lo indica cada cadena es simple y esto significa que solo tiene una entrada y una salida y es secuencial porque la la salida de una cadena sera la entrada de otra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823f9201-3249-4c54-8b82-77351c478720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32f3079-6dc1-4020-b5f6-aa3540a7c49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(openai_api_key=token, temperature=0.0, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")\n",
    "\n",
    "# chain 1\n",
    "chain_1 = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f980a2f-8c43-40bf-9dfa-739e1c318eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 words description for the following \\\n",
    "    company:{company_name}\"\n",
    ")\n",
    "# chain 2\n",
    "chain_2 = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c64446-15a4-45c1-a95d-620bca9b4ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cadena_simple_secuencial = SimpleSequentialChain(\n",
    "    chains=[chain_1, chain_2],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab4b16b-1ff8-46b8-a6b8-da1aa6b97aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cadena_simple_secuencial.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eeee50-9e01-4da8-b034-3cb62418dce8",
   "metadata": {},
   "source": [
    "## Sequential Chain\n",
    "\n",
    "En este caso podemos hacer que una cadena tenga como entrada la salida de mas de una cadena. Por ello ahora utilizaremos el atributo **output_key** para darle un nombre a cada salida y luego poder utilizarla mas tarde como entrada en otra cadena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f49692-764f-4b6a-967b-fb5cb89f21af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce219b6-a0d6-48da-8240-e2a23b69e633",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(openai_api_key=token, temperature=0.0, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# prompt template 1: translate to english\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to english:\"\n",
    "    \"\\n\\n{Review}\"\n",
    ")\n",
    "# chain 1: input= Review and output= English_Review\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"English_Review\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d4b065-ca4f-4155-9b52-d3eba505f30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you summarize the following review in 1 sentence:\"\n",
    "    \"\\n\\n{English_Review}\"\n",
    ")\n",
    "# chain 2: input= English_Review and output= summary\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"summary\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2c5579-9b9a-441d-aee1-1e364d195f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 3: translate to english\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review:\\n\\n{Review}\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"language\"\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5159ff-7fdc-4f5f-ac42-90eea8a7448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 4: follow up message\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary in the specified language:\"\n",
    "    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",
    ")\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"followup_message\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8ea91d-d057-4bee-9122-f36737cb3a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_chain: input= Review \n",
    "# and output= English_Review,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"English_Review\", \"summary\",\"followup_message\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cf3743-fdf6-4220-acb2-2fb4b53167b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"Esta comida estuvo deliciosa\"\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0b5aec-953e-46d8-bee2-6548ad169f49",
   "metadata": {},
   "source": [
    "## Router Chain\n",
    "\n",
    "### Esto ha sido deprecado. Actualizar el tutorial a Router class\n",
    "- https://python.langchain.com/docs/modules/chains/foundational/router\n",
    "\n",
    "En este caso podemos elegir que cadena queremos utilizar de acuerdo al tipo de salida de la cadena anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edab7c6-27da-4ba5-baaf-58446cc8e9aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc7fb339-bcca-4465-ad77-58a6da37edb3",
   "metadata": {},
   "source": [
    "## Referencias:\n",
    "Esta unidad esta basada en el [curso de Andrew Ng de Deeplearning.ai](https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6358cb17-9275-4517-8624-2aea9cccb24d",
   "metadata": {},
   "source": [
    "# Fin: [Volver al contenido del curso](https://www.freecodingtour.com/cursos/espanol/deeplearning/deeplearning.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
