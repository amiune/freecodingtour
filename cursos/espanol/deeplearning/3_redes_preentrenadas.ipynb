{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "355a45d0-f340-4a55-8249-0a86a4f06bec",
   "metadata": {},
   "source": [
    "# Cajas Negras Preentrenadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd637aed-b023-450b-9d28-80a630a73d99",
   "metadata": {},
   "source": [
    "Estas cajas negras de deep learning que pueden aprender a partir de imagenes y texto han sido estudiadas y puestas en practica por miles de cientificos e ingenieros en los ultimos años. Por ello hay muchas arquitecturas diferentes y diferentes modelos.\n",
    "\n",
    "Muchos de estos modelos han sido entrenados con imagenes y texto obtenidos de internet y puestos a disposicion de cualquier programador para que pueda descargarlos y utilizarlos sin tener que entrenarlos nuevamente. **Estas cajas negras se llaman modelos preentrenados.**\n",
    "\n",
    "Ya que crear y entrenar un modelo desde cero lleva muchisimo trabajo, esfuerzo y tiempo de computo, en este curso nos enfocaremos en utilizar solamente modelos preentrenados y luego ajustarlos a nuestras necesidades mediante lo que se conoce como el procedimiento de finetuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6b3f52-2121-4891-a518-c562833b3b3e",
   "metadata": {},
   "source": [
    "## Librerias\n",
    "\n",
    "Existen multiples librerias que nos permiten descargar y utilizar estos modelos preentrenados de forma sencilla y seguramente iran apareciendo mas. Aqui nos veremos solo veremos algunas de las mas usadas.\n",
    "\n",
    "Veamos ahora como utilizar los modelos preentrenados de la libreria **Huggingface**, una de las librerias mas utilizadas mas simples de utilizar que ademas es open source:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f8350d-dd2a-4559-a2c1-7bffe2eda5ee",
   "metadata": {},
   "source": [
    "### Huggingface\n",
    "\n",
    "Esta libreria ordena los modelos de acuerdo a la tarea que necesitemos realizar, podemos ver todas las categorias disponibles en el siguiente link: https://huggingface.co/tasks\n",
    "\n",
    "Veamos aqui las categorias:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ce9646-b950-436b-a20d-45fb59a6e620",
   "metadata": {},
   "source": [
    "### Vision\n",
    "\n",
    "Si necesitamos trabajar con imagenes entonces la categoria vision nos clasifica los modelos preentrenados para realizar las siguientes tareas:\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"img/hf_vision.png\" width=\"600\"/>\n",
    "</div>\n",
    "\n",
    "Veamos como utiliza uno de estos modelos, intentemos adivinar que raza de perro es la de la siguiente imagen: https://t1.ea.ltmcdn.com/es/posts/5/6/2/10_caracteristicas_de_los_perros_24265_600_square.jpg\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"https://t1.ea.ltmcdn.com/es/posts/5/6/2/10_caracteristicas_de_los_perros_24265_600_square.jpg\" width=\"200\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd53ade-1603-406a-8185-2750b7015336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# si no tenemos instaladas las librerias la podemos instalar usando pip\n",
    "! pip install -U accelerate\n",
    "! pip install -U transformers[torch]\n",
    "! pip install -U diffusers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db0dc15-d01d-4d8c-8ac7-98db58de5c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos la libreria\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e561639-10fe-43ca-ac9d-b4118339ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos la clase que nos permite descargar el modelo para \n",
    "# clasificacion de imagenes\n",
    "clasificador = pipeline(\"image-classification\", model=\"google/vit-base-patch16-224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6df555-666c-4a7a-af81-bf28172d2419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizamos el clasificador para saber que hay en la imagen\n",
    "url = 'https://t1.ea.ltmcdn.com/es/posts/5/6/2/10_caracteristicas_de_los_perros_24265_600_square.jpg'\n",
    "clasificador(images=url, top_k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d55c0f4-8a16-4b8a-8c99-f932a169b7d2",
   "metadata": {},
   "source": [
    "#### Ejercicio 1:\n",
    "\n",
    "Intentar clasificar las [imagenes de bananas maduras](https://github.com/amiune/freecodingtour/raw/main/cursos/espanol/deeplearning/data/bananas/) y frescas utilizando el modelo anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14a3610-ac99-4338-8875-29a25ed858aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribir aqui la solucion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3408ea-a7d0-45dc-b997-49ca1abc1c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Solucion Ejercicio 1: {display-mode:\"form\"}\n",
    "\n",
    "from transformers import pipeline\n",
    "clasificador = pipeline(\"image-classification\", model=\"google/vit-base-patch16-224\")\n",
    "\n",
    "# Lista de nombres de las imagenes\n",
    "nombres_imagenes = [f'normal{i}.jpeg' for i in range(1,6)]\n",
    "nombres_imagenes.extend([f'madura{i}.jpeg' for i in range(1,6)])\n",
    "PATH = 'https://github.com/amiune/freecodingtour/raw/main/cursos/espanol/deeplearning/data/bananas/'\n",
    "for nombre_imagen in nombres_imagenes:\n",
    "    predictions = clasificador(PATH + nombre_imagen, top_k=1)\n",
    "    print(nombre_imagen, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee60368-dd83-42a7-aae5-cbef3d9ec84b",
   "metadata": {},
   "source": [
    "### Procesamiento de Lenguaje Natural\n",
    "\n",
    "Si necesitamos trabajar con texto entonces la categoria vision nos clasifica los modelos preentrenados para realizar las siguientes tareas:\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"img/hf_nlp.png\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69305d63-4e9f-400a-8a63-395b6de61593",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba98152-6ee3-4c43-aa88-4bf0cd9f4dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04055a0-3c22-4d58-953b-a322a392662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"\"\"Paris is the capital and most populous city of France, \n",
    "with an estimated population of 2,175,601 residents as of 2018, \n",
    "in an area of more than 105 square kilometres (41 square miles). \n",
    "The City of Paris is the centre and seat of government of the region \n",
    "and province of Île-de-France, or Paris Region, which has an estimated \n",
    "population of 12,174,880, or about 18 percent of \n",
    "the population of France as of 2017.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54897494",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer(texto, max_length=30, min_length=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb831f32-760f-412e-b1d6-70a6da495b4a",
   "metadata": {},
   "source": [
    "#### Ejercicio 2:\n",
    "\n",
    "Intentar clasificar las peliculas de comedia y terror utilizando un modelo de text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d7ece3d-3b0b-48c1-8efc-80ca8bee3d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribir aqui la solucion\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c4e863-ae23-49df-972f-300f1df1df4c",
   "metadata": {},
   "source": [
    "### Audio\n",
    "\n",
    "Si necesitamos trabajar con audio entonces la categoria vision nos clasifica los modelos preentrenados para realizar las siguientes tareas:\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"img/hf_audio.png\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18068d96-5a9d-4307-9868-a33d87767f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd40b803-de1e-4aeb-bf81-0ac7e412770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesizer = pipeline(\"text-to-speech\", \"suno/bark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eea5ae-beaf-46f6-9237-25e7558ebd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesizer(\"Look I am generating speech in three lines of code!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a0aec3-e307-46b8-b614-a3bf3ca943b5",
   "metadata": {},
   "source": [
    "### Multimodal\n",
    "\n",
    "Si necesitamos trabajar con una conbinacion de imagenes, texto y audio entonces la categoria vision nos clasifica los modelos preentrenados para realizar las siguientes tareas:\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"img/hf_multimodal.png\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcabb50d-0730-492b-8ba6-b7b5bf514a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83794ce3-1c7b-4d45-b941-b2248fd47b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "captioner = pipeline(\"image-to-text\",model=\"Salesforce/blip-image-captioning-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5fec6d-9b72-4e81-8ae5-18f3b5d5f6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "captioner(\"https://huggingface.co/datasets/Narsil/image_dummy/resolve/main/parrots.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aba3f0-4822-4084-bdf4-748c391fdc70",
   "metadata": {},
   "source": [
    "# Otras librerias open source interesantes:\n",
    "- [GitHub Models: alternativa a HuggingFace](https://github.blog/news-insights/product-news/introducing-github-models/)\n",
    "- [Supervision para tareas de computer vision](https://github.com/roboflow/supervision?tab=readme-ov-file)\n",
    "- [YOLO](https://github.com/ultralytics/ultralytics) [tutorial](https://www.youtube.com/watch?v=hf9MaEazc9s)\n",
    "- [torchchat: Chat with LLMs Everywhere](https://github.com/pytorch/torchchat)\n",
    "- [Image Generation](https://blackforestlabs.ai/)\n",
    "- [Stable Fast 3D](https://stability.ai/news/introducing-stable-fast-3d)\n",
    "\n",
    "## Notebooks con ejemplos:\n",
    "- [YOLOv11 examples](https://colab.research.google.com/github/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb#scrollTo=WFPJIQl_L5HT)\n",
    "- [Supervision examples](https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/train-yolov8-object-detection-on-custom-dataset.ipynb)\n",
    "- [Zero shot with dino and roboflow](https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/zero-shot-object-detection-with-grounding-dino.ipynb)\n",
    "- [Count objects crossing the line](https://colab.research.google.com/github/roboflow/supervision/blob/develop/docs/notebooks/count-objects-crossing-the-line.ipynb)\n",
    "- [Supervision cheatsheet](https://roboflow.github.io/cheatsheet-supervision/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94244657-107f-4e36-9d08-88ba57823f71",
   "metadata": {},
   "source": [
    "# Fin: [Volver al contenido del curso](https://www.freecodingtour.com/cursos/espanol/deeplearning/deeplearning.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
