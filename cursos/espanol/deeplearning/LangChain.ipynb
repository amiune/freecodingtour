{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b2efdf0-8ee2-4f99-a0eb-2eb7c2edd822",
   "metadata": {},
   "source": [
    "# LangChain\n",
    "\n",
    "Como vimos anteriormente podemos utilizar estos Large Language Models entrenados para hacerles preguntas y recibir sus respuestas.\n",
    "\n",
    "Es como si tuvieramos una funcion que recibe un texto como entrada y devuelve un texto como salida. Donde el texto de entrada puede ser cualquier pregunta y el texto de respuesta sera esta respuesta magica que es capaz de darnos un LLM. \n",
    "\n",
    "Esto parece simple y tonto pero es el sue√±o de cualquier programador. Es como si fuera posible hacer una busqueda en google y luego poder hacer web scrapping del mejor resultado pero de manera mucho mas sencilla.\n",
    "\n",
    "LangChain es una API que nos permite realizar estas consultas a los LLM y poder parsear el resultado de forma mas simple. Veamos la diferencia entre consultar directamente a OpenAI como hicimos en la unidad anterior y hacerlo utilizando LangChain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2f2e42-9ea5-4bae-a378-7261ee68406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai --upgrade --quiet\n",
    "!pip install langchain --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c19ca64-06f3-419c-9be0-61d5862812a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Cargar token desde google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "with open('drive/MyDrive/Tokens/openai.txt','r') as f:\n",
    "    token = f.read()\n",
    "    openai.api_key = token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17b86c2-43e4-4927-be38-81eb68826c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "chat = ChatOpenAI(openai_api_key=token, temperature=0.0, model=\"gpt-3.5-turbo\")\n",
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96580451-87f5-4029-88d7-168a9f64f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template_string = \"\"\"Traduce el siguiente texto \\\n",
    "que esta delimitado por comillas triples \\\n",
    "al siguiente estilo {estilo}. \\\n",
    "texto: ```{texto}```\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "\n",
    "message = prompt_template.format_messages(\n",
    "                    estilo=\"rapero\",\n",
    "                    texto=\"Estimado Carlos, hoy no podre ir a tomar \\\n",
    "                    el te a tu casa porque estoy resfriado.\")\n",
    "\n",
    "response = chat(message)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c6d859-ee5c-4755-bf60-e239be536589",
   "metadata": {},
   "source": [
    "## Parsear la salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d284fbd6-4b24-4b1d-8239-2720d59bac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee1bdb3-8d7f-4d65-98c9-e1672883619d",
   "metadata": {},
   "source": [
    "### Genero el schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6ba52a-3b3c-41ca-887b-09546f1d6cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "precio_schema = ResponseSchema(name=\"precio\",\n",
    "                             description=\"Cual ha sido el precio pagado?\\\n",
    "                             Si no se encuentra la informacion devolver -1.\")\n",
    "calificacion_schema = ResponseSchema(name=\"calificacion\",\n",
    "                                      description=\"Que calificacion se le asigno al restaurante?\\\n",
    "                                      Si no se encuentra la informacion devolver -1.\")\n",
    "\n",
    "response_schemas = [precio_schema, \n",
    "                    calificacion_schema]\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a0a7b8-bede-426e-bff3-88009afa1742",
   "metadata": {},
   "source": [
    "### Consulto al LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65672fb9-4f82-48f0-bc3a-9e7940593983",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_review = \"\"\"\\\n",
    "La comida fue espectacular, lo mejor la tortilla de patatas \\\n",
    "y la tarta de queso. El precio bien, en total costo 23 euros.\n",
    "Le doy una calificacion de 8.3.\n",
    "\"\"\"\n",
    "\n",
    "review_template_2 = \"\"\"\\\n",
    "Para el siguiente texto obtener la siguiente informacion:\n",
    "\n",
    "precio: Cual ha sido el precio pagado?\\\n",
    "Si no se encuentra la informacion devolver -1.\n",
    "\n",
    "calificacion: Que calificacion se le asigno al restaurante?\\\n",
    "Si no se encuentra la informacion devolver -1.\n",
    "\n",
    "texto: {texto}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=review_template_2)\n",
    "\n",
    "messages = prompt.format_messages(text=customer_review, \n",
    "                                format_instructions=format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d9c945-8de6-4a81-a002-aade247f8dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b337c1-2b98-41b5-8563-31d9d9a67a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = output_parser.parse(response.content)\n",
    "print(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db189017-eac0-4857-b9ec-c330ece271ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
