{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "355a45d0-f340-4a55-8249-0a86a4f06bec",
   "metadata": {},
   "source": [
    "# De imagenes a vectores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb282c99-1446-4578-801a-c70891049134",
   "metadata": {},
   "source": [
    "Como vimos en el [Curso de ciencia de datos](https://www.freecodingtour.com/cursos/espanol/datascience/datascience.html) tenemos cajas negras que podemos entrenar mediante una tabla de entrenamiento que contiene filas con ejemplos y su respectivo resultado esperado. Estas filas son numeros que llamamos vectores. \n",
    "\n",
    "Que pasa si queremos entrenar una caja negra para que reconozca imagenes, por ejemplo, queremos entrenar una caja negra para que reconozca si una imagen tiene un gato o un perro. En ese caso nuestra tabla de entrenamiento estara compuesta por filas que tienen una imagen en vez de numeros como vemos a continuacion:\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"img/tabla_perros_gatos.png\" width=\"700\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6b3690-5dfd-495d-85f6-995988bc804d",
   "metadata": {},
   "source": [
    "Sabiendo que nuestras cajas negras funcionan muy bien con numeros en cada fila (vectores), la pregunta es como podemos hacer para convertir estas imagenes en vectores que las representen bien.\n",
    "\n",
    "Como ya la mayoria de la gente sabe las imagenes estan compuestas por pequeños cuadraditos llamados pixeles y cada pixel tiene un numero que representa un color. Veamos un ejemplo de una imagen de 3x3 pixeles de distintos colores y pongamosle un numero distinto para cada color:\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"img/pixeles.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "NOTA: Hay muchas formas de establecer que numero le corresponde a cada color pero eso no importa por el momento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7062e1-35f9-4b46-991a-c7c053255ff9",
   "metadata": {},
   "source": [
    "Sabiendo esto podemos convertir una imagen a un vector (fila de numeros ordenados) de forma muy simple. Solamente ponemos uno despues de otro y esta imagen quedaria convertida en el siguiente vector:\n",
    "(54,13,74,89,27,62,31,66,77)\n",
    "\n",
    "Y nuestra tabla de perros y gatos quedaria de la siguiente forma:\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"img/tabla_perros_gatos_vectores.png\" width=\"700\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19fdc01-e0f8-471c-81c7-c21c599653c1",
   "metadata": {},
   "source": [
    "Lamentablemente esta forma de convertir las imagenes a vectores no funciona muy bien para entrenar a nuestras cajas negras porque los pixeles se relacionan entre si para crear bordes, ojos, patas, etc y al ponerlos por separado las cajas negras no logran captar estas relaciones pero los cientificos empezaron a probar distintas formas de convertir las imagenes en vectores a partir de los cuales las cajas negras puedan aprender.\n",
    "\n",
    "Un ejemplo de estas pruebas fue la aplicacion de filtros a las imagenes. Un filtro en particular es el de deteccion de bordes que convierte una imagen de la siguiente manera:\n",
    "\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"img/deteccion_bordes.png\" width=\"500\" alt=\"Imagen de wikipedia\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "Estos filtros se llaman de convolucion y se consiguen multiplicando los pixeles por matrices. Este proceso es el que les da el nombre a las famosas redes convolucionales.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"img/2D_Convolution_Animation.gif\" width=\"500\" alt=\"Imagen de wikipedia\"/>\n",
    "</div>\n",
    "\n",
    "Luego se creo otra arquitectura, Vision Transformers, que tambien permite transformar imagenes a vectores de manera muy efectiva. Esta arquitectura se basa en lo descubierto al intentar transformar texto a vectores.\n",
    "\n",
    "Por el momento existen estas dos arquitecturas que funcionan bien para convertir imagenes en vectores:\n",
    "- Redes Convolucionales\n",
    "- Redes Tranformers\n",
    "\n",
    "Y en cada una de estas arquitecturas existen muchas variaciones.\n",
    "\n",
    "Ambas arquitecturas realizan un proceso similar aunque de distinta forma y es el de encontrar formas y propiedades particulares en las imagenes para generar vectores que se podria decir que tienen una forma similar a la siguiente:\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"img/tabla_perros_gatos_vectores2.png\" width=\"700\"/>\n",
    "</div>\n",
    "\n",
    "Afortunadamente todo este proceso que llevo muchos años de prueba y error fue introducido adentro de las cajas negras y estas cajas negras mas complejas que aprenden solas a como convertir las imagenes en vectores para poder aprender se llaman cajas negras de deep learning.\n",
    "\n",
    "Probablemente en el futuro se sigan creando nuevas arquitecturas para convertir imagenes en vectores que sean aun mejores que las mencionadas.\n",
    "\n",
    "Si quieres profundizar mas en como esta compuesta la arquitectura interna de dichas cajas negras hay mas informacion en las unidades avanzadas de este curso pero no es necesario conocer en profundidad como funcionan para poder utilizarlas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96807e7b-c0bb-4dd3-a1bd-c952c5b90a7a",
   "metadata": {},
   "source": [
    "### Ejercicio 1:\n",
    "\n",
    "Cargar una imagen de una banana madura y una normal en la notebook de jupyter usando la libreria PIL de python y convertir la imagen en:\n",
    "\n",
    "1. Un vector de un solo elemento que es el promedio del color\n",
    "2. Un vector de tres elementos con el promedio de R, G y B\n",
    "3. Un vector aplanado de nxm elementos que son todos los pixeles de la imagen en una sola dimension\n",
    "\n",
    "Entrenar un modelo de ML de la libreria sklearn con dichos vectores para poder clasificar las imagenes y ver los distintos resultados.\n",
    "\n",
    "Utilizar las imagenes provistas en: \n",
    "- https://github.com/amiune/freecodingtour/tree/main/cursos/espanol/deeplearning/data/bananas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db6162a-3211-4a50-95d1-d545da508e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribir aqui la solucion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123b3184-2bb0-4558-840c-b4bef5250c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Solucion Ejercicio 1: Paso 1 {display-mode:\"form\"}\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Abre la imagen\n",
    "imagen = Image.open(\"https://github.com/amiune/freecodingtour/raw/main/cursos/espanol/deeplearning/data/bananas/normal1.jpeg\")\n",
    "imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aab719-f810-450e-bdf7-1e2a8892d678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Solucion Ejercicio 1: Paso 2 {display-mode:\"form\"}\n",
    "\n",
    "# Convierte la imagen en un arreglo NumPy\n",
    "imagen_array = np.array(imagen)\n",
    "imagen_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61c3925-edba-40be-a441-83b5f82a764c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Solucion Ejercicio 1: Paso 3 {display-mode:\"form\"}\n",
    "\n",
    "# Calcula el promedio de todos los píxeles\n",
    "promedio_pixeles = np.mean(imagen_array)\n",
    "promedio_pixeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5869c06a-3e4f-43a9-9fac-8b1124ef09f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Solucion Ejercicio 1: Paso 4 {display-mode:\"form\"}\n",
    "\n",
    "# Calcula el promedio de cada canal de color (R, G y B)\n",
    "promedio_canal_R = np.mean(imagen_array[:, :, 0])\n",
    "promedio_canal_G = np.mean(imagen_array[:, :, 1])\n",
    "promedio_canal_B = np.mean(imagen_array[:, :, 2])\n",
    "promedio_canal_R,promedio_canal_G,promedio_canal_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ed4468-64df-4038-a903-1623a88f2934",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Solucion Ejercicio 1: Paso 5 {display-mode:\"form\"}\n",
    "\n",
    "# Aplana el arreglo en un vector\n",
    "imagen_vector_plano = imagen_array.flatten()\n",
    "imagen_vector_plano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce481eed-1c4e-4fc8-b7a0-b3b3425074a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Solucion Ejercicio 1: Paso 6 {display-mode:\"form\"}\n",
    "\n",
    "# Url donde se encuentran las imagenes\n",
    "PATH = 'https://github.com/amiune/freecodingtour/raw/main/cursos/espanol/deeplearning/data/bananas/'\n",
    "# Tamaño al que vamos a estandarizar a todas las imagenes\n",
    "IMAGE_SIZE = (256, 256)\n",
    "\n",
    "# Diccionario para guardar los resultados\n",
    "vectores = {}\n",
    "\n",
    "# Lista de nombres de las imagenes\n",
    "nombres_imagenes = [f'normal{i}.jpeg' for i in range(5)]\n",
    "nombres_imagenes.extend([f'madura{i}.jpeg' for i in range(5)]\n",
    "\n",
    "for nombre_imagen in nombres_imagenes:\n",
    "    # Cargar la imagen\n",
    "    with Image.open(PATH + nombre_imagen) as img:\n",
    "        # Convertir a RGBA\n",
    "        if img.mode != 'RGBA':\n",
    "            img = img.convert('RGBA')\n",
    "        \n",
    "            # Hacer las imagenes del mismo tamaño\n",
    "            img = img.resize(standard_size, Image.ANTIALIAS)\n",
    "\n",
    "            # Convertir a numpy array\n",
    "            img_array = np.array(img)\n",
    "\n",
    "            # Identificar los pixeles que no sean transparentes\n",
    "            non_transparent_mask = img_array[:, :, 3] != 0\n",
    "\n",
    "            # Calcular el color promedio\n",
    "            avg_color = np.mean(img_array[non_transparent_mask][:, :3], axis=0)\n",
    "\n",
    "            # Calcular el color promedio por canal\n",
    "            avg_rgb = [np.mean(img_array[non_transparent_mask][:, i]) for i in range(3)]\n",
    "\n",
    "            # Aplanar la matriz\n",
    "            flattened = img_array[non_transparent_mask][:, :3].flatten()\n",
    "\n",
    "            # Guardar los resultados\n",
    "            vectores[filename] = {\n",
    "                'avg_color': avg_color,\n",
    "                'avg_rgb': avg_rgb,\n",
    "                'flattened': flattened,\n",
    "                'clase': nombre_imagen[:6]\n",
    "            }\n",
    "\n",
    "vectores  # Mostrar los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8728c714-695f-43a4-9338-28677430697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Solucion Ejercicio 1: Paso 7 {display-mode:\"form\"}\n",
    "\n",
    "X = np.array([value['avg_rgb'] for key, value in vectores.items()])\n",
    "y = np.array([value['clase'] for key, value in vectores.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c6120f-e069-419b-b069-52b0cdf63ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Solucion Ejercicio 1: Paso 8 {display-mode:\"form\"}\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Dividir el dataset en train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5089b4e3-2a3b-40a0-9e98-e2df59a218eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Solucion Ejercicio 1: Paso 9 {display-mode:\"form\"}\n",
    "\n",
    "# Predecir\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94244657-107f-4e36-9d08-88ba57823f71",
   "metadata": {},
   "source": [
    "# Fin: [Volver al contenido del curso](https://www.freecodingtour.com/cursos/espanol/deeplearning/deeplearning.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550a1445-e61b-4b6b-a06a-ad6c2dfdff38",
   "metadata": {},
   "source": [
    "Dos imagenes de esta unidad fueron obtenidas de wikipedia:\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Edge_detection\n",
    "- https://en.wikipedia.org/wiki/Kernel_(image_processing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
