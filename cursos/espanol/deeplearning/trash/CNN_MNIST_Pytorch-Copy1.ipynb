{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ffe360a-bd96-428d-a26e-0554907e8c8c",
   "metadata": {},
   "source": [
    "# CNN con Pytorch\n",
    "\n",
    "Repetimos el ejemplo de Keras pero ahora utilizando Pytorch. Como veremos es mucho mas complejo ya que nos permite definir mas en detalle todo el proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459a19f6-be89-491f-a719-c59d914cfe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b33e7c-8930-43b3-9fc4-01d98a09cb3e",
   "metadata": {},
   "source": [
    "Definimos la arquitectura de la CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4929034-bdcb-4aa9-b91d-f524535abf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Net, self).__init__()\n",
    "        # Input shape will be inferred automatically in PyTorch\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1) # Assuming input channels is 1 (grayscale)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Max pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        \n",
    "        # Global average pooling can be done by adaptive pooling in PyTorch\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply the first two convolution layers with relu\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        \n",
    "        # Apply max pooling\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Apply the next two convolution layers with relu\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        \n",
    "        # Apply global average pooling\n",
    "        x = self.global_avg_pool(x)\n",
    "        \n",
    "        # Flatten the output for the dropout and dense layer\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Apply dropout\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Apply the fully connected layer with softmax\n",
    "        x = self.fc(x)\n",
    "        output = F.softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b8d564-915f-4d7d-a3f9-5dbca76659d5",
   "metadata": {},
   "source": [
    "Definimos como el modelo debe cargar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbcbd3d-a2fe-4abb-bcd8-f588393fbf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMNISTDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = torch.tensor(self.encodings[idx]).to(device)\n",
    "        label = torch.tensor(self.labels[idx]).to(device)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebba3e15-ce5e-4969-b762-038d10e5810e",
   "metadata": {},
   "source": [
    "Definimos el proceso de entrenamiento paso a paso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e69f539-9be9-49e1-96f9-ee1a014b1102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c730aae3-219e-4adc-961f-75623706e0e0",
   "metadata": {},
   "source": [
    "Definimos el proceso de validacion paso a paso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67e04e7-027b-459a-ad02-cab655b7ab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, device, val_loader):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            print(data.shape)\n",
    "            output = model(data)\n",
    "            val_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        val_loss, correct, len(val_loader.dataset),\n",
    "        100. * correct / len(val_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03f913e-b00c-44b6-8931-d4bcfd0465d2",
   "metadata": {},
   "source": [
    "Cargamos los datos igual que hicimos antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5067b433-267d-43b4-a1d2-e8dcddcdcf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(\"./data/mnist/mnist_train.csv.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"./data/mnist/extracted/\")\n",
    "with zipfile.ZipFile(\"./data/mnist/mnist_test.csv.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"./data/mnist/extracted/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900fe51f-dc5e-41bc-a266-f45a2f2f7438",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./data/mnist/extracted/mnist_train.csv\")\n",
    "\n",
    "x_train = train_df.iloc[:,1:].values\n",
    "y_train = train_df.iloc[:,0].values\n",
    "\n",
    "# Hacer que cada pixel este entre 0 y 1\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "\n",
    "# Cambiar la forma de unidimensional de (784) a bidimensional (28, 28, 1)\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca78333-78a7-46d2-8aa8-98923a91c8c5",
   "metadata": {},
   "source": [
    "El input tensor en Keras tiene que tener la forma  **(batch_size, height, width, channels)**\n",
    "\n",
    "El input tensor en PyTorch tiene que tener la forma **(batch_size, channels, height, width)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab6bcce-9036-474a-a530-e735d186523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4944a94f-c7f9-4569-8e5f-96bc62683033",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.transpose((0, 3, 1, 2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc85cf7-47d9-4847-95a2-644fe0db5a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.transpose((0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1899d618-a352-4d5a-9e87-d1cbc0bc06a6",
   "metadata": {},
   "source": [
    "Separamos manualmente los conjuntos de entrenamiento y validacion.\n",
    "Antes lo hacia automaticamente keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f13f02e-658f-48bd-bfeb-ea2b637ffc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930cc266-b129-4aab-8627-9b89370aebbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "train_dataset = CustomMNISTDataset(x_train, y_train)\n",
    "val_dataset = CustomMNISTDataset(x_val, y_val)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15c6194-c28b-4770-8598-9b437ca12dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b199726f-068c-4b48-9f92-879ab5235486",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0][0].permute(1, 2, 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7107064e-f969-434c-9c06-75cdb6d2f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(train_dataset[0][0].permute(1, 2, 0), interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ce7f8b-35da-44ab-9828-ae4bed21788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(1, 3):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    validation(model, device, val_loader)\n",
    "\n",
    "#torch.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11578344-cd86-4b4f-a490-a0e229207946",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./data/mnist/extracted/mnist_test.csv\")\n",
    "\n",
    "x_test = test.iloc[:,1:].values\n",
    "y_test = test.iloc[:,0].values\n",
    "\n",
    "# Hacer que cada pixel este entre 0 y 1\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "# Cambiar la forma de unidimensional de (784) a bidimensional (28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "#Cambiar al formato de pytorch\n",
    "x_test = x_test.transpose((0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbfff04-af51-40a8-844c-4f26b0c8f89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test[0:1,:].shape #(batch_size, layers, witdh, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884cde6e-300c-4ccd-937f-fbb4797e041e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor(x_test[0:1,:]).to(device)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe41556-66fa-4c69-a7cf-bb2a69a06c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(tensor[0].permute(1, 2, 0), interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3edc307-56df-4960-b401-358a557e3ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c047ebf0-d6ff-4573-9bcb-95f14ba6287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33b9373-77c8-4ce7-a88d-40e7af443e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.argmax(axis=-1).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c7230e-a643-4a50-b89a-dc51271a8303",
   "metadata": {},
   "source": [
    "## Referencias:\n",
    "\n",
    "- https://github.com/pytorch/examples/blob/main/mnist/main.py\n",
    "- https://www.kaggle.com/datasets/oddrationale/mnist-in-csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
